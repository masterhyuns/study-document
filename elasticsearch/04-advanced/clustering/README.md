# ðŸŒ Elasticsearch Clustering ì™„ë²½ ê°€ì´ë“œ

## ðŸŽ¯ ëª©í‘œ

Elasticsearch í´ëŸ¬ìŠ¤í„°ì˜ ì„¤ê³„, êµ¬ì¶•, ìš´ì˜ ë° ìµœì í™”ë¥¼ ë§ˆìŠ¤í„°í•©ë‹ˆë‹¤.

## ðŸ—ï¸ í´ëŸ¬ìŠ¤í„° ì•„í‚¤í…ì²˜

### ë…¸ë“œ ì—­í• ê³¼ êµ¬ì„±

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Elasticsearch Cluster                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Master Node  â”‚  â”‚ Master Node  â”‚  â”‚ Master Node  â”‚â”‚
â”‚  â”‚  (master)    â”‚  â”‚  (master)    â”‚  â”‚  (master)    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Data Node   â”‚  â”‚  Data Node   â”‚  â”‚  Data Node   â”‚â”‚
â”‚  â”‚(data, ingest)â”‚  â”‚(data, ingest)â”‚  â”‚   (data)     â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚Coordinate    â”‚  â”‚   ML Node    â”‚  â”‚ Transform    â”‚â”‚
â”‚  â”‚    Node      â”‚  â”‚              â”‚  â”‚    Node      â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ”§ ë…¸ë“œ íƒ€ìž…ë³„ ì„¤ì •

### Master Node ì„¤ì •

```yaml
# master-node.yml
cluster.name: production-cluster
node.name: master-01
node.roles: [ master ]

# ë§ˆìŠ¤í„° ë…¸ë“œ ì „ìš© ì„¤ì •
cluster.initial_master_nodes:
  - master-01
  - master-02
  - master-03

# ìµœì†Œ ë§ˆìŠ¤í„° ë…¸ë“œ ìˆ˜ (ê³¼ë°˜ìˆ˜)
discovery.zen.minimum_master_nodes: 2

# ë„¤íŠ¸ì›Œí¬ ì„¤ì •
network.host: 0.0.0.0
http.port: 9200
transport.port: 9300

# ë””ìŠ¤ì»¤ë²„ë¦¬ ì„¤ì •
discovery.seed_hosts:
  - master-01:9300
  - master-02:9300
  - master-03:9300

# ë§ˆìŠ¤í„° ë…¸ë“œëŠ” ë°ì´í„° ì €ìž¥ ì•ˆí•¨
path.data: /var/lib/elasticsearch
path.logs: /var/log/elasticsearch

# JVM íž™ ì„¤ì • (ìž‘ê²Œ ìœ ì§€)
# jvm.options: -Xms2g -Xmx2g
```

### Data Node ì„¤ì •

```yaml
# data-node.yml
cluster.name: production-cluster
node.name: data-01
node.roles: [ data, ingest ]

# ë°ì´í„° ë…¸ë“œ ì„¤ì •
node.attr.box_type: hot  # hot, warm, cold
node.attr.zone: zone-1

# ë„¤íŠ¸ì›Œí¬
network.host: 0.0.0.0
http.port: 9200
transport.port: 9300

# ë””ìŠ¤ì»¤ë²„ë¦¬
discovery.seed_hosts:
  - master-01:9300
  - master-02:9300
  - master-03:9300

# ìŠ¤í† ë¦¬ì§€
path.data:
  - /mnt/disk1/elasticsearch
  - /mnt/disk2/elasticsearch
  - /mnt/disk3/elasticsearch
path.logs: /var/log/elasticsearch

# ì„±ëŠ¥ ì„¤ì •
indices.memory.index_buffer_size: 30%
indices.queries.cache.size: 15%
indices.fielddata.cache.size: 30%

# Thread pools
thread_pool:
  write:
    size: 10
    queue_size: 1000
  search:
    size: 30
    queue_size: 1000
```

### Coordinating Node ì„¤ì •

```yaml
# coordinating-node.yml
cluster.name: production-cluster
node.name: coord-01
node.roles: []  # ë¹ˆ ë°°ì—´ = coordinating only

# ë„¤íŠ¸ì›Œí¬
network.host: 0.0.0.0
http.port: 9200
transport.port: 9300

# ë””ìŠ¤ì»¤ë²„ë¦¬
discovery.seed_hosts:
  - master-01:9300
  - master-02:9300
  - master-03:9300

# ìºì‹œ ì„¤ì • (ê²€ìƒ‰ ìµœì í™”)
indices.queries.cache.size: 20%
indices.requests.cache.size: 5%

# JVM ì„¤ì • (ì¤‘ê°„ í¬ê¸°)
# jvm.options: -Xms8g -Xmx8g
```

## ðŸŒ¡ï¸ Hot-Warm-Cold ì•„í‚¤í…ì²˜

### ë°ì´í„° ë¼ì´í”„ì‚¬ì´í´ ê´€ë¦¬

```json
// Hot-Warm-Cold ì¸ë±ìŠ¤ í…œí”Œë¦¿
PUT _index_template/logs-template
{
  "index_patterns": ["logs-*"],
  "template": {
    "settings": {
      "number_of_shards": 3,
      "number_of_replicas": 1,
      "index.routing.allocation.include.box_type": "hot",
      "index.lifecycle.name": "logs-lifecycle-policy"
    }
  }
}

// ILM Policy
PUT _ilm/policy/logs-lifecycle-policy
{
  "policy": {
    "phases": {
      "hot": {
        "min_age": "0ms",
        "actions": {
          "rollover": {
            "max_age": "7d",
            "max_size": "50GB"
          },
          "set_priority": {
            "priority": 100
          }
        }
      },
      "warm": {
        "min_age": "7d",
        "actions": {
          "shrink": {
            "number_of_shards": 1
          },
          "allocate": {
            "include": {
              "box_type": "warm"
            }
          },
          "forcemerge": {
            "max_num_segments": 1
          },
          "set_priority": {
            "priority": 50
          }
        }
      },
      "cold": {
        "min_age": "30d",
        "actions": {
          "allocate": {
            "include": {
              "box_type": "cold"
            },
            "number_of_replicas": 0
          },
          "freeze": {},
          "set_priority": {
            "priority": 0
          }
        }
      },
      "delete": {
        "min_age": "90d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
```

### ë…¸ë“œë³„ í•˜ë“œì›¨ì–´ ìŠ¤íŽ™

```javascript
// cluster-design.js
const clusterDesign = {
  hot_nodes: {
    count: 3,
    specs: {
      cpu: "16 cores",
      ram: "64GB",
      storage: "2TB NVMe SSD",
      network: "10Gbps"
    },
    jvm_heap: "30GB",
    node_roles: ["data_hot", "ingest"]
  },
  
  warm_nodes: {
    count: 3,
    specs: {
      cpu: "8 cores",
      ram: "32GB",
      storage: "8TB SSD",
      network: "1Gbps"
    },
    jvm_heap: "16GB",
    node_roles: ["data_warm"]
  },
  
  cold_nodes: {
    count: 2,
    specs: {
      cpu: "4 cores",
      ram: "16GB",
      storage: "20TB HDD",
      network: "1Gbps"
    },
    jvm_heap: "8GB",
    node_roles: ["data_cold"]
  },
  
  master_nodes: {
    count: 3,
    specs: {
      cpu: "4 cores",
      ram: "8GB",
      storage: "100GB SSD",
      network: "1Gbps"
    },
    jvm_heap: "4GB",
    node_roles: ["master"]
  }
};
```

## ðŸ”„ í´ëŸ¬ìŠ¤í„° ê´€ë¦¬

### ìƒ¤ë“œ í• ë‹¹ ì œì–´

```json
// ìƒ¤ë“œ ìž¬í• ë‹¹ ë¹„í™œì„±í™” (ìœ ì§€ë³´ìˆ˜ ì‹œ)
PUT _cluster/settings
{
  "transient": {
    "cluster.routing.allocation.enable": "none"
  }
}

// íŠ¹ì • ë…¸ë“œ ì œì™¸
PUT _cluster/settings
{
  "transient": {
    "cluster.routing.allocation.exclude._ip": "10.0.0.1"
  }
}

// ìƒ¤ë“œ ìž¬í• ë‹¹ í™œì„±í™”
PUT _cluster/settings
{
  "transient": {
    "cluster.routing.allocation.enable": "all"
  }
}

// ìƒ¤ë“œ ì´ë™
POST _cluster/reroute
{
  "commands": [
    {
      "move": {
        "index": "products",
        "shard": 0,
        "from_node": "node-1",
        "to_node": "node-2"
      }
    }
  ]
}

// Allocation Awareness
PUT _cluster/settings
{
  "persistent": {
    "cluster.routing.allocation.awareness.attributes": "zone",
    "cluster.routing.allocation.awareness.force.zone.values": "zone-1,zone-2"
  }
}
```

### í´ëŸ¬ìŠ¤í„° ìƒíƒœ ëª¨ë‹ˆí„°ë§

```javascript
// cluster-monitor.js
class ClusterMonitor {
  constructor(client) {
    this.client = client;
  }

  /**
   * í´ëŸ¬ìŠ¤í„° ê±´ê°• ìƒíƒœ í™•ì¸
   */
  async checkHealth() {
    const health = await this.client.cluster.health({
      level: 'indices',
      timeout: '30s'
    });

    const alerts = [];
    
    if (health.status === 'red') {
      alerts.push({
        severity: 'critical',
        message: 'Cluster status is RED'
      });
    } else if (health.status === 'yellow') {
      alerts.push({
        severity: 'warning',
        message: 'Cluster status is YELLOW'
      });
    }

    if (health.unassigned_shards > 0) {
      alerts.push({
        severity: 'warning',
        message: `${health.unassigned_shards} unassigned shards`
      });
    }

    return {
      health,
      alerts
    };
  }

  /**
   * ë…¸ë“œ ìƒíƒœ ëª¨ë‹ˆí„°ë§
   */
  async monitorNodes() {
    const stats = await this.client.nodes.stats({
      metric: ['jvm', 'os', 'fs', 'indices']
    });

    const nodes = [];
    
    for (const [nodeId, node] of Object.entries(stats.nodes)) {
      const nodeInfo = {
        id: nodeId,
        name: node.name,
        roles: node.roles,
        jvm: {
          heap_used_percent: node.jvm.mem.heap_used_percent,
          gc_count: node.jvm.gc.collectors.young.collection_count +
                    node.jvm.gc.collectors.old.collection_count
        },
        cpu: {
          percent: node.os.cpu.percent,
          load_average: node.os.cpu.load_average
        },
        disk: {
          available: node.fs.total.available_in_bytes,
          used_percent: ((node.fs.total.total_in_bytes - 
                         node.fs.total.available_in_bytes) / 
                         node.fs.total.total_in_bytes * 100)
        },
        indices: {
          docs: node.indices.docs.count,
          size: node.indices.store.size_in_bytes
        }
      };

      // ê²½ê³  í™•ì¸
      if (nodeInfo.jvm.heap_used_percent > 85) {
        nodeInfo.warning = 'High heap usage';
      }
      if (nodeInfo.disk.used_percent > 85) {
        nodeInfo.warning = 'High disk usage';
      }

      nodes.push(nodeInfo);
    }

    return nodes;
  }

  /**
   * ìƒ¤ë“œ ë¶„í¬ ë¶„ì„
   */
  async analyzeShardDistribution() {
    const shards = await this.client.cat.shards({
      format: 'json',
      h: ['index', 'shard', 'prirep', 'state', 'node', 'store']
    });

    const nodeDistribution = {};
    
    shards.forEach(shard => {
      if (!nodeDistribution[shard.node]) {
        nodeDistribution[shard.node] = {
          primary: 0,
          replica: 0,
          total: 0,
          size: 0
        };
      }

      const node = nodeDistribution[shard.node];
      node.total++;
      
      if (shard.prirep === 'p') {
        node.primary++;
      } else {
        node.replica++;
      }

      // í¬ê¸° íŒŒì‹± (ì˜ˆ: "1.2gb" -> bytes)
      const size = this.parseSize(shard.store);
      node.size += size;
    });

    return nodeDistribution;
  }

  parseSize(sizeStr) {
    const units = {
      'b': 1,
      'kb': 1024,
      'mb': 1024 * 1024,
      'gb': 1024 * 1024 * 1024,
      'tb': 1024 * 1024 * 1024 * 1024
    };
    
    const match = sizeStr.match(/^([\d.]+)([a-z]+)$/i);
    if (match) {
      return parseFloat(match[1]) * (units[match[2].toLowerCase()] || 1);
    }
    return 0;
  }
}
```

## ðŸš€ í´ëŸ¬ìŠ¤í„° í™•ìž¥ ì „ëžµ

### ìˆ˜í‰ í™•ìž¥ (Scale Out)

```bash
#!/bin/bash
# add-data-node.sh

# ìƒˆ ë°ì´í„° ë…¸ë“œ ì¶”ê°€ ìŠ¤í¬ë¦½íŠ¸
NODE_NAME="data-04"
CLUSTER_NAME="production-cluster"
MASTER_NODES="master-01:9300,master-02:9300,master-03:9300"

# Elasticsearch ì„¤ì¹˜
sudo apt-get update
sudo apt-get install -y elasticsearch=8.11.0

# ì„¤ì • íŒŒì¼ ìƒì„±
cat > /etc/elasticsearch/elasticsearch.yml <<EOF
cluster.name: ${CLUSTER_NAME}
node.name: ${NODE_NAME}
node.roles: [ data ]
network.host: 0.0.0.0
discovery.seed_hosts: [${MASTER_NODES}]
path.data: /var/lib/elasticsearch
path.logs: /var/log/elasticsearch
EOF

# JVM ì„¤ì •
echo "-Xms16g" > /etc/elasticsearch/jvm.options.d/heap.options
echo "-Xmx16g" >> /etc/elasticsearch/jvm.options.d/heap.options

# ì„œë¹„ìŠ¤ ì‹œìž‘
sudo systemctl start elasticsearch
sudo systemctl enable elasticsearch

# í´ëŸ¬ìŠ¤í„° ì¡°ì¸ í™•ì¸
sleep 30
curl -X GET "localhost:9200/_cat/nodes?v"
```

### ìˆ˜ì§ í™•ìž¥ (Scale Up)

```javascript
// vertical-scaling.js
class VerticalScaling {
  /**
   * ë…¸ë“œ ë¦¬ì†ŒìŠ¤ ì—…ê·¸ë ˆì´ë“œ ì ˆì°¨
   */
  async upgradeNode(nodeName) {
    // 1. ìƒ¤ë“œ ìž¬í• ë‹¹ ë¹„í™œì„±í™”
    await this.client.cluster.putSettings({
      body: {
        transient: {
          "cluster.routing.allocation.enable": "none"
        }
      }
    });

    // 2. ë…¸ë“œì—ì„œ ìƒ¤ë“œ ì´ë™
    await this.client.cluster.putSettings({
      body: {
        transient: {
          "cluster.routing.allocation.exclude._name": nodeName
        }
      }
    });

    // 3. ìƒ¤ë“œ ì´ë™ ëŒ€ê¸°
    await this.waitForShardRelocation(nodeName);

    // 4. ë…¸ë“œ ì¢…ë£Œ
    console.log(`Shutdown node: ${nodeName}`);
    // ì‹¤ì œ ì¢…ë£Œ ëª…ë ¹ ì‹¤í–‰

    // 5. í•˜ë“œì›¨ì–´ ì—…ê·¸ë ˆì´ë“œ
    console.log('Performing hardware upgrade...');
    // RAM ì¶”ê°€, CPU ì—…ê·¸ë ˆì´ë“œ ë“±

    // 6. ë…¸ë“œ ìž¬ì‹œìž‘
    console.log(`Restart node: ${nodeName}`);
    // ë…¸ë“œ ìž¬ì‹œìž‘ ëª…ë ¹

    // 7. ìƒ¤ë“œ ìž¬í• ë‹¹ í™œì„±í™”
    await this.client.cluster.putSettings({
      body: {
        transient: {
          "cluster.routing.allocation.enable": "all",
          "cluster.routing.allocation.exclude._name": null
        }
      }
    });
  }

  async waitForShardRelocation(nodeName) {
    while (true) {
      const shards = await this.client.cat.shards({
        format: 'json',
        h: ['node']
      });

      const nodeShards = shards.filter(s => s.node === nodeName);
      
      if (nodeShards.length === 0) {
        break;
      }

      console.log(`Waiting for ${nodeShards.length} shards to relocate...`);
      await new Promise(resolve => setTimeout(resolve, 5000));
    }
  }
}
```

## ðŸ›¡ï¸ í´ëŸ¬ìŠ¤í„° ë³µì›ë ¥

### Split Brain ë°©ì§€

```yaml
# elasticsearch.yml
# ìµœì†Œ ë§ˆìŠ¤í„° ë…¸ë“œ ì„¤ì • (ê³¼ë°˜ìˆ˜)
discovery.zen.minimum_master_nodes: 2  # 3ê°œ ë§ˆìŠ¤í„° ì¤‘ 2ê°œ

# ë…¸ë“œ ê°„ í†µì‹  íƒ€ìž„ì•„ì›ƒ
discovery.zen.ping_timeout: 10s
discovery.zen.join_timeout: 30s

# ë§ˆìŠ¤í„° ì„ ì¶œ ì„¤ì •
cluster.election.duration: 1m
cluster.fault_detection.leader_check.interval: 1s
```

### ìžë™ ë³µêµ¬ ì„¤ì •

```json
// ìžë™ ë³µêµ¬ ì •ì±…
PUT _cluster/settings
{
  "persistent": {
    // ìƒ¤ë“œ ë³µêµ¬ ë™ì‹œ ì‹¤í–‰ ìˆ˜
    "cluster.routing.allocation.node_concurrent_recoveries": 2,
    
    // ë…¸ë“œë‹¹ ë™ì‹œ ë³µêµ¬
    "cluster.routing.allocation.node_initial_primaries_recoveries": 4,
    
    // ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ ì œí•œ
    "indices.recovery.max_bytes_per_sec": "50mb",
    
    // ë³µêµ¬ ìž¬ì‹œë„
    "indices.recovery.retry_delay_state_sync": "500ms",
    "indices.recovery.retry_delay_network": "5s",
    
    // ë””ìŠ¤í¬ ì›Œí„°ë§ˆí¬
    "cluster.routing.allocation.disk.watermark.low": "85%",
    "cluster.routing.allocation.disk.watermark.high": "90%",
    "cluster.routing.allocation.disk.watermark.flood_stage": "95%"
  }
}
```

## ðŸ“Š í´ëŸ¬ìŠ¤í„° ë²¤ì¹˜ë§ˆí‚¹

### Rallyë¥¼ ì´ìš©í•œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

```bash
# Rally ì„¤ì¹˜
pip install esrally

# ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
esrally race --distribution-version=8.11.0 \
  --target-hosts=localhost:9200 \
  --pipeline=benchmark-only \
  --challenge=append-no-conflicts \
  --track=geonames

# ì»¤ìŠ¤í…€ íŠ¸ëž™ ìƒì„±
cat > custom-track.json <<EOF
{
  "version": 2,
  "description": "Custom benchmark track",
  "indices": [
    {
      "name": "test-index",
      "body": "test-index.json"
    }
  ],
  "corpora": [
    {
      "name": "test-docs",
      "documents": [
        {
          "source-file": "documents.json.bz2",
          "document-count": 1000000
        }
      ]
    }
  ],
  "schedule": [
    {
      "operation": "bulk",
      "warmup-time-period": 120,
      "time-period": 300,
      "clients": 8
    }
  ]
}
EOF
```

### í´ëŸ¬ìŠ¤í„° ìš©ëŸ‰ ê³„íš

```javascript
// capacity-planning.js
class CapacityPlanner {
  /**
   * í•„ìš” ë…¸ë“œ ìˆ˜ ê³„ì‚°
   */
  calculateNodeRequirements(requirements) {
    const {
      totalDataGB,
      dailyIngestionGB,
      queryQPS,
      replicationFactor = 1,
      growthRate = 0.2
    } = requirements;

    // ìŠ¤í† ë¦¬ì§€ ê³„ì‚°
    const totalStorageNeeded = totalDataGB * (1 + replicationFactor);
    const storageWithGrowth = totalStorageNeeded * (1 + growthRate);
    
    // ê¶Œìž¥ ìƒ¤ë“œ í¬ê¸°: 20-40GB
    const optimalShardSize = 30;
    const numberOfShards = Math.ceil(totalDataGB / optimalShardSize);
    
    // ë…¸ë“œë‹¹ ê¶Œìž¥ ìƒ¤ë“œ ìˆ˜: 20ê°œ
    const shardsPerNode = 20;
    const minDataNodes = Math.ceil(
      (numberOfShards * (1 + replicationFactor)) / shardsPerNode
    );

    // ì²˜ë¦¬ëŸ‰ ê¸°ë°˜ ê³„ì‚°
    const qpsPerNode = 100; // ë…¸ë“œë‹¹ ì²˜ë¦¬ ê°€ëŠ¥ QPS
    const minNodesForQuery = Math.ceil(queryQPS / qpsPerNode);

    // ìµœì¢… ë…¸ë“œ ìˆ˜
    const recommendedDataNodes = Math.max(minDataNodes, minNodesForQuery);

    return {
      shards: numberOfShards,
      replicas: replicationFactor,
      dataNodes: recommendedDataNodes,
      masterNodes: 3, // í•­ìƒ í™€ìˆ˜
      coordinatingNodes: Math.ceil(recommendedDataNodes / 3),
      totalStorage: storageWithGrowth,
      estimatedCost: this.estimateCost(recommendedDataNodes)
    };
  }

  estimateCost(nodeCount) {
    const costPerNode = {
      hot: 500,   // $/month
      warm: 200,  // $/month
      cold: 100   // $/month
    };

    // 70% hot, 20% warm, 10% cold ê°€ì •
    const hotNodes = Math.ceil(nodeCount * 0.7);
    const warmNodes = Math.ceil(nodeCount * 0.2);
    const coldNodes = Math.ceil(nodeCount * 0.1);

    return {
      monthly: (hotNodes * costPerNode.hot) + 
               (warmNodes * costPerNode.warm) + 
               (coldNodes * costPerNode.cold),
      yearly: this.monthly * 12
    };
  }
}
```

## ðŸŽ¯ ë² ìŠ¤íŠ¸ í”„ëž™í‹°ìŠ¤

### 1. í´ëŸ¬ìŠ¤í„° ì„¤ê³„
- **ë§ˆìŠ¤í„° ë…¸ë“œ**: í•­ìƒ í™€ìˆ˜ (3, 5, 7)
- **ë°ì´í„° ë…¸ë“œ**: CPU/RAMë³´ë‹¤ ìŠ¤í† ë¦¬ì§€ ì¤‘ì‹¬
- **ì¡°ì • ë…¸ë“œ**: ë¶€í•˜ ë¶„ì‚°ìš©ìœ¼ë¡œ í™œìš©

### 2. ìƒ¤ë“œ ì „ëžµ
- **ìƒ¤ë“œ í¬ê¸°**: 20-40GB ìœ ì§€
- **ìƒ¤ë“œ ìˆ˜**: ë…¸ë“œë‹¹ 20ê°œ ì´í•˜
- **ë³µì œë³¸**: ìµœì†Œ 1ê°œ ì´ìƒ

### 3. ëª¨ë‹ˆí„°ë§
- **ë©”íŠ¸ë¦­ ìˆ˜ì§‘**: Metricbeat í™œìš©
- **ë¡œê·¸ ìˆ˜ì§‘**: Filebeat + Logstash
- **ì•Œë¦¼ ì„¤ì •**: Watcher ë˜ëŠ” ElastAlert

### 4. ë°±ì—… ì „ëžµ
- **ìŠ¤ëƒ…ìƒ·**: ì •ê¸°ì  ìŠ¤ëƒ…ìƒ· ìƒì„±
- **ì›ê²© ì €ìž¥ì†Œ**: S3, GCS ë“± í™œìš©
- **ë³µêµ¬ í…ŒìŠ¤íŠ¸**: ì •ê¸°ì  ë³µêµ¬ í›ˆë ¨

---

ðŸ’¡ **ë‹¤ìŒ ë‹¨ê³„**: [ì„±ëŠ¥ ìµœì í™”](../performance/README.md)ì—ì„œ ì„±ëŠ¥ íŠœë‹ì„ í•™ìŠµí•˜ì„¸ìš”!