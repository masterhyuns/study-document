# ğŸ—ï¸ Kubernetes ì•„í‚¤í…ì²˜ ì™„ë²½ ì´í•´

> ğŸ’¡ **ëª©í‘œ**: Kubernetesì˜ ë‚´ë¶€ ë™ì‘ ì›ë¦¬ë¥¼ ê¹Šì´ ì´í•´í•˜ê³ , ê° ì»´í¬ë„ŒíŠ¸ê°€ ì–´ë–»ê²Œ í˜‘ë ¥í•˜ëŠ”ì§€ íŒŒì•…í•©ë‹ˆë‹¤.

## ğŸ“š ëª©ì°¨

1. [**ì•„í‚¤í…ì²˜ ì „ì²´ êµ¬ì¡°**](#ì•„í‚¤í…ì²˜-ì „ì²´-êµ¬ì¡°)
2. [**Control Plane ìƒì„¸**](#control-plane-ìƒì„¸)
3. [**Worker Node ìƒì„¸**](#worker-node-ìƒì„¸)
4. [**í†µì‹  íë¦„**](#í†µì‹ -íë¦„)
5. [**ê³ ê°€ìš©ì„±(HA) êµ¬ì„±**](#ê³ ê°€ìš©ì„±ha-êµ¬ì„±)
6. [**ì‹¤ìŠµ: ì»´í¬ë„ŒíŠ¸ ëª¨ë‹ˆí„°ë§**](#ì‹¤ìŠµ-ì»´í¬ë„ŒíŠ¸-ëª¨ë‹ˆí„°ë§)

---

## ğŸ›ï¸ ì•„í‚¤í…ì²˜ ì „ì²´ êµ¬ì¡°

### Kubernetes í´ëŸ¬ìŠ¤í„° êµ¬ì¡°ë„

```mermaid
graph TB
    subgraph "ì‚¬ìš©ì/í´ë¼ì´ì–¸íŠ¸"
        U1[kubectl]
        U2[API Client]
        U3[Web UI]
    end
    
    subgraph "Control Plane (Master Nodes)"
        API[API Server<br/>kube-apiserver]
        ETCD[(etcd<br/>ë¶„ì‚° ì €ì¥ì†Œ)]
        SCHED[Scheduler<br/>kube-scheduler]
        CM[Controller Manager<br/>kube-controller-manager]
        CCM[Cloud Controller Manager<br/>cloud-controller-manager]
        
        API --> ETCD
        SCHED --> API
        CM --> API
        CCM --> API
    end
    
    subgraph "Worker Node 1"
        K1[kubelet]
        KP1[kube-proxy]
        CR1[Container Runtime]
        P1[Pods]
        
        K1 --> CR1
        CR1 --> P1
        KP1 --> P1
    end
    
    subgraph "Worker Node 2"
        K2[kubelet]
        KP2[kube-proxy]
        CR2[Container Runtime]
        P2[Pods]
        
        K2 --> CR2
        CR2 --> P2
        KP2 --> P2
    end
    
    U1 --> API
    U2 --> API
    U3 --> API
    
    API --> K1
    API --> K2
```

### ğŸ¯ ê° ì»´í¬ë„ŒíŠ¸ì˜ ì—­í• 

| ì»´í¬ë„ŒíŠ¸ | ìœ„ì¹˜ | ì£¼ìš” ì—­í•  | í¬íŠ¸ |
|---------|------|----------|------|
| **kube-apiserver** | Control Plane | ëª¨ë“  API ìš”ì²­ ì²˜ë¦¬ | 6443 (HTTPS) |
| **etcd** | Control Plane | í´ëŸ¬ìŠ¤í„° ë°ì´í„° ì €ì¥ | 2379-2380 |
| **kube-scheduler** | Control Plane | Pod ë°°ì¹˜ ê²°ì • | 10251 |
| **kube-controller-manager** | Control Plane | ì»¨íŠ¸ë¡¤ëŸ¬ ì‹¤í–‰ | 10252 |
| **kubelet** | Worker Node | Pod ìƒëª…ì£¼ê¸° ê´€ë¦¬ | 10250 |
| **kube-proxy** | Worker Node | ë„¤íŠ¸ì›Œí¬ í”„ë¡ì‹œ | 10256 |

---

## ğŸ›ï¸ Control Plane ìƒì„¸

### 1. API Server (kube-apiserver)

API ServerëŠ” Kubernetesì˜ ì¤‘ì•™ ê´€ë¦¬ ì§€ì ì…ë‹ˆë‹¤.

```mermaid
sequenceDiagram
    participant Client as kubectl
    participant API as API Server
    participant Auth as Authentication
    participant Authz as Authorization
    participant AC as Admission Control
    participant ETCD as etcd
    
    Client->>API: API ìš”ì²­
    API->>Auth: ì¸ì¦ í™•ì¸
    Auth-->>API: ì¸ì¦ ì„±ê³µ
    API->>Authz: ê¶Œí•œ í™•ì¸
    Authz-->>API: ê¶Œí•œ ìŠ¹ì¸
    API->>AC: Admission Control
    AC-->>API: ê²€ì¦/ë³€ê²½
    API->>ETCD: ë°ì´í„° ì €ì¥
    ETCD-->>API: ì €ì¥ ì™„ë£Œ
    API-->>Client: ì‘ë‹µ
```

**ì£¼ìš” ê¸°ëŠ¥:**
```yaml
# API Server ì„¤ì • ì˜ˆì‹œ
apiVersion: v1
kind: Pod
metadata:
  name: kube-apiserver
  namespace: kube-system
spec:
  containers:
  - name: kube-apiserver
    image: k8s.gcr.io/kube-apiserver:v1.27.0
    command:
    - kube-apiserver
    - --advertise-address=10.0.1.10
    - --allow-privileged=true
    - --authorization-mode=Node,RBAC  # ê¶Œí•œ ëª¨ë“œ
    - --client-ca-file=/etc/kubernetes/pki/ca.crt
    - --enable-admission-plugins=NodeRestriction,ResourceQuota
    - --etcd-servers=https://127.0.0.1:2379  # etcd ì—°ê²°
    - --secure-port=6443
```

### 2. etcd (ë¶„ì‚° í‚¤-ê°’ ì €ì¥ì†Œ)

etcdëŠ” ëª¨ë“  í´ëŸ¬ìŠ¤í„° ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë¶„ì‚° ì €ì¥ì†Œì…ë‹ˆë‹¤.

```bash
# etcdì— ì €ì¥ë˜ëŠ” ë°ì´í„° êµ¬ì¡°
/registry/
â”œâ”€â”€ pods/
â”‚   â”œâ”€â”€ default/
â”‚   â”‚   â”œâ”€â”€ my-pod
â”‚   â”‚   â””â”€â”€ web-app
â”‚   â””â”€â”€ kube-system/
â”‚       â”œâ”€â”€ coredns
â”‚       â””â”€â”€ kube-proxy
â”œâ”€â”€ services/
â”‚   â””â”€â”€ default/
â”‚       â””â”€â”€ kubernetes
â”œâ”€â”€ deployments/
â”œâ”€â”€ configmaps/
â”œâ”€â”€ secrets/
â””â”€â”€ namespaces/
```

**etcd ë°±ì—…ê³¼ ë³µêµ¬:**
```bash
# etcd ë°±ì—…
ETCDCTL_API=3 etcdctl \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  snapshot save backup.db

# ë°±ì—… í™•ì¸
ETCDCTL_API=3 etcdctl snapshot status backup.db

# etcd ë³µêµ¬
ETCDCTL_API=3 etcdctl snapshot restore backup.db \
  --data-dir=/var/lib/etcd-backup
```

### 3. Scheduler (kube-scheduler)

SchedulerëŠ” ìƒˆë¡œìš´ Podë¥¼ ì–´ëŠ Nodeì— ë°°ì¹˜í• ì§€ ê²°ì •í•©ë‹ˆë‹¤.

```mermaid
graph LR
    subgraph "Scheduling Process"
        A[ìƒˆ Pod ìƒì„± ìš”ì²­] --> B{Filtering<br/>ì‹¤í–‰ ê°€ëŠ¥í•œ ë…¸ë“œ}
        B --> C{Scoring<br/>ì ìˆ˜ ê³„ì‚°}
        C --> D[ìµœì  ë…¸ë“œ ì„ íƒ]
        D --> E[Pod í• ë‹¹]
    end
```

**ìŠ¤ì¼€ì¤„ë§ ê²°ì • ìš”ì†Œ:**
```yaml
# Podì˜ ìŠ¤ì¼€ì¤„ë§ ìš”êµ¬ì‚¬í•­ ì˜ˆì‹œ
apiVersion: v1
kind: Pod
metadata:
  name: gpu-pod
spec:
  # Node Selector
  nodeSelector:
    gpu: "true"
    disktype: "ssd"
  
  # Resource Requirements
  containers:
  - name: cuda-app
    image: nvidia/cuda
    resources:
      requests:
        memory: "8Gi"
        cpu: "4"
        nvidia.com/gpu: "1"
      limits:
        memory: "16Gi"
        cpu: "8"
        nvidia.com/gpu: "2"
  
  # Affinity Rules
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: kubernetes.io/e2e-az-name
            operator: In
            values:
            - az1
            - az2
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - gpu-app
        topologyKey: kubernetes.io/hostname
```

### 4. Controller Manager

Controller ManagerëŠ” ì—¬ëŸ¬ ì»¨íŠ¸ë¡¤ëŸ¬ë¥¼ ì‹¤í–‰í•˜ì—¬ í´ëŸ¬ìŠ¤í„° ìƒíƒœë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.

```mermaid
graph TB
    subgraph "Controller Manager"
        CM[Controller Manager]
        CM --> RC[ReplicaSet Controller]
        CM --> DC[Deployment Controller]
        CM --> SC[Service Controller]
        CM --> NC[Node Controller]
        CM --> EC[Endpoint Controller]
        CM --> SAC[ServiceAccount Controller]
        CM --> PVC[PersistentVolume Controller]
    end
    
    RC --> |"ê´€ì°°"|Current[í˜„ì¬ ìƒíƒœ]
    RC --> |"ë¹„êµ"|Desired[ì›í•˜ëŠ” ìƒíƒœ]
    RC --> |"ì¡°ì •"|Action[ë™ì‘ ìˆ˜í–‰]
```

**Controller ë™ì‘ ì˜ˆì‹œ - ReplicaSet Controller:**
```yaml
# ì›í•˜ëŠ” ìƒíƒœ: 3ê°œ replica
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: web-rs
spec:
  replicas: 3  # ì›í•˜ëŠ” ìƒíƒœ
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
    spec:
      containers:
      - name: nginx
        image: nginx
```

```bash
# Controllerì˜ ì¡°ì • ê³¼ì •
# 1. í˜„ì¬ ìƒíƒœ í™•ì¸: 2ê°œ Pod ì‹¤í–‰ ì¤‘
# 2. ì›í•˜ëŠ” ìƒíƒœ: 3ê°œ Pod
# 3. ì°¨ì´ ê³„ì‚°: 1ê°œ ë¶€ì¡±
# 4. ë™ì‘: 1ê°œ Pod ì¶”ê°€ ìƒì„±
```

---

## ğŸ–¥ï¸ Worker Node ìƒì„¸

### 1. kubelet

kubeletì€ ê° Nodeì—ì„œ ì‹¤í–‰ë˜ë©° Podì˜ ìƒëª…ì£¼ê¸°ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.

```mermaid
sequenceDiagram
    participant API as API Server
    participant K as kubelet
    participant CR as Container Runtime
    participant C as Container
    
    API->>K: Pod ìƒì„± ìš”ì²­
    K->>K: Pod Spec í™•ì¸
    K->>CR: Container ìƒì„± ìš”ì²­
    CR->>C: Container ì‹œì‘
    C-->>CR: ì‹¤í–‰ ì¤‘
    CR-->>K: Container ìƒíƒœ
    K-->>API: Pod ìƒíƒœ ì—…ë°ì´íŠ¸
    
    loop Health Check
        K->>C: Liveness Probe
        C-->>K: ì‘ë‹µ
        K->>C: Readiness Probe
        C-->>K: ì‘ë‹µ
    end
```

**kubelet ì„¤ì •:**
```yaml
# kubelet-config.yaml
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
clusterDNS:
- 10.96.0.10
clusterDomain: cluster.local
containerRuntime: docker
maxPods: 110
podPidsLimit: 4096
healthzBindAddress: 127.0.0.1
healthzPort: 10248
readOnlyPort: 0
cgroupDriver: systemd
authentication:
  webhook:
    enabled: true
authorization:
  mode: Webhook
```

### 2. kube-proxy

kube-proxyëŠ” Serviceì˜ ë„¤íŠ¸ì›Œí¬ ê·œì¹™ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.

```mermaid
graph LR
    subgraph "kube-proxy ëª¨ë“œ"
        A[userspace ëª¨ë“œ<br/>ëŠë¦¼, êµ¬ì‹] 
        B[iptables ëª¨ë“œ<br/>í‘œì¤€, ë¹ ë¦„]
        C[IPVS ëª¨ë“œ<br/>ê³ ì„±ëŠ¥, í™•ì¥ì„±]
    end
```

**iptables ê·œì¹™ ì˜ˆì‹œ:**
```bash
# Service: my-service (ClusterIP: 10.96.0.100)
# Endpoints: 10.244.1.5:80, 10.244.2.6:80

# kube-proxyê°€ ìƒì„±í•˜ëŠ” iptables ê·œì¹™
iptables -t nat -A KUBE-SERVICES \
  -d 10.96.0.100/32 -p tcp --dport 80 \
  -j KUBE-SVC-XXXXX

# ë¡œë“œë°¸ëŸ°ì‹± ê·œì¹™
iptables -t nat -A KUBE-SVC-XXXXX \
  -m statistic --mode random --probability 0.5 \
  -j KUBE-SEP-AAAAA  # Pod 1

iptables -t nat -A KUBE-SVC-XXXXX \
  -j KUBE-SEP-BBBBB  # Pod 2
```

### 3. Container Runtime

Container Runtimeì€ ì‹¤ì œ ì»¨í…Œì´ë„ˆë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

```yaml
# Container Runtime Interface (CRI) êµ¬í˜„ì²´ë“¤
Container_Runtimes:
  - Docker:
      deprecated: true
      version: "< 1.24"
      
  - containerd:
      recommended: true
      features:
        - "ë„¤ì´í‹°ë¸Œ Kubernetes ì§€ì›"
        - "ê²½ëŸ‰í™”"
        - "ë†’ì€ ì„±ëŠ¥"
      
  - CRI-O:
      optimized_for: "Kubernetes"
      features:
        - "OCI í‘œì¤€ ì¤€ìˆ˜"
        - "ìµœì†Œ ê¸°ëŠ¥ ì§‘í•©"
```

---

## ğŸ”„ í†µì‹  íë¦„

### Pod ìƒì„± ê³¼ì • ìƒì„¸

```mermaid
sequenceDiagram
    participant User as ì‚¬ìš©ì
    participant API as API Server
    participant ETCD as etcd
    participant Sched as Scheduler
    participant CM as Controller Manager
    participant Kub as kubelet
    participant Cont as Container Runtime
    
    User->>API: kubectl create deployment
    API->>ETCD: Deployment ì €ì¥
    
    CM->>API: Deployment ê°ì§€
    CM->>API: ReplicaSet ìƒì„±
    API->>ETCD: ReplicaSet ì €ì¥
    
    CM->>API: ReplicaSet ê°ì§€
    CM->>API: Pod ìƒì„± (unscheduled)
    API->>ETCD: Pod ì €ì¥
    
    Sched->>API: Unscheduled Pod ê°ì§€
    Sched->>Sched: ë…¸ë“œ ì„ íƒ
    Sched->>API: Podì— ë…¸ë“œ í• ë‹¹
    API->>ETCD: Pod ì—…ë°ì´íŠ¸
    
    Kub->>API: í• ë‹¹ëœ Pod ê°ì§€
    Kub->>Cont: Container ìƒì„±
    Cont->>Cont: Image Pull & Start
    Cont-->>Kub: Container ì‹¤í–‰ ì¤‘
    Kub-->>API: Pod ìƒíƒœ ì—…ë°ì´íŠ¸
    API-->>User: Pod Running
```

### Service í†µì‹  íë¦„

```yaml
# 1. Service ìƒì„±
apiVersion: v1
kind: Service
metadata:
  name: web-service
spec:
  selector:
    app: web
  ports:
  - port: 80
    targetPort: 8080
```

```mermaid
graph LR
    subgraph "Service Discovery"
        C[Client Pod] -->|DNS ì§ˆì˜| D[CoreDNS]
        D -->|IP ë°˜í™˜| C
        C -->|ìš”ì²­| S[Service<br/>10.96.0.100:80]
        S -->|iptables/IPVS| P1[Pod1<br/>10.244.1.5:8080]
        S -->|ë¡œë“œë°¸ëŸ°ì‹±| P2[Pod2<br/>10.244.2.6:8080]
    end
```

---

## ğŸ” ê³ ê°€ìš©ì„±(HA) êµ¬ì„±

### HA Control Plane êµ¬ì„±

```mermaid
graph TB
    subgraph "HA Control Plane"
        LB[Load Balancer<br/>VIP: 10.0.0.100]
        
        subgraph "Master 1"
            API1[API Server]
            ETCD1[(etcd)]
            SCHED1[Scheduler]
            CM1[Controller Manager]
        end
        
        subgraph "Master 2"
            API2[API Server]
            ETCD2[(etcd)]
            SCHED2[Scheduler-Standby]
            CM2[Controller Manager-Standby]
        end
        
        subgraph "Master 3"
            API3[API Server]
            ETCD3[(etcd)]
            SCHED3[Scheduler-Standby]
            CM3[Controller Manager-Standby]
        end
        
        LB --> API1
        LB --> API2
        LB --> API3
        
        ETCD1 -.->|Raft í•©ì˜| ETCD2
        ETCD2 -.->|Raft í•©ì˜| ETCD3
        ETCD3 -.->|Raft í•©ì˜| ETCD1
    end
    
    subgraph "Worker Nodes"
        W1[Worker 1]
        W2[Worker 2]
        W3[Worker 3]
    end
    
    LB --> W1
    LB --> W2
    LB --> W3
```

### etcd í´ëŸ¬ìŠ¤í„° êµ¬ì„±

```bash
# etcd í´ëŸ¬ìŠ¤í„° ì´ˆê¸°í™”
etcd --name etcd1 \
  --initial-advertise-peer-urls http://10.0.1.10:2380 \
  --listen-peer-urls http://10.0.1.10:2380 \
  --listen-client-urls http://10.0.1.10:2379,http://127.0.0.1:2379 \
  --advertise-client-urls http://10.0.1.10:2379 \
  --initial-cluster-token etcd-cluster-1 \
  --initial-cluster etcd1=http://10.0.1.10:2380,etcd2=http://10.0.1.11:2380,etcd3=http://10.0.1.12:2380 \
  --initial-cluster-state new
```

### Leader Election

```yaml
# Schedulerì™€ Controller Managerì˜ Leader Election
apiVersion: v1
kind: ConfigMap
metadata:
  name: kube-scheduler
  namespace: kube-system
data:
  config.yaml: |
    apiVersion: kubescheduler.config.k8s.io/v1beta3
    kind: KubeSchedulerConfiguration
    leaderElection:
      leaderElect: true
      leaseDuration: 15s
      renewDeadline: 10s
      retryPeriod: 2s
      resourceLock: leases
      resourceName: kube-scheduler
      resourceNamespace: kube-system
```

---

## ğŸ”¬ ì‹¤ìŠµ: ì»´í¬ë„ŒíŠ¸ ëª¨ë‹ˆí„°ë§

### ì‹¤ìŠµ 1: Control Plane ì»´í¬ë„ŒíŠ¸ ìƒíƒœ í™•ì¸

```bash
# 1. Control Plane ì»´í¬ë„ŒíŠ¸ Pod í™•ì¸
kubectl get pods -n kube-system

# 2. ê° ì»´í¬ë„ŒíŠ¸ ë¡œê·¸ í™•ì¸
kubectl logs -n kube-system kube-apiserver-master
kubectl logs -n kube-system kube-scheduler-master
kubectl logs -n kube-system kube-controller-manager-master

# 3. ì»´í¬ë„ŒíŠ¸ ìƒíƒœ í™•ì¸
kubectl get componentstatuses

# 4. etcd ìƒíƒœ í™•ì¸
ETCDCTL_API=3 etcdctl \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key \
  endpoint health
```

### ì‹¤ìŠµ 2: kubelet ë””ë²„ê¹…

```bash
# 1. kubelet ìƒíƒœ í™•ì¸
systemctl status kubelet

# 2. kubelet ë¡œê·¸ í™•ì¸
journalctl -u kubelet -f

# 3. kubelet ì„¤ì • í™•ì¸
cat /var/lib/kubelet/config.yaml

# 4. kubelet ë©”íŠ¸ë¦­ í™•ì¸
curl -k https://localhost:10250/metrics

# 5. Node ìƒíƒœ í™•ì¸
kubectl describe node <node-name>
```

### ì‹¤ìŠµ 3: kube-proxy ëª¨ë‹ˆí„°ë§

```bash
# 1. kube-proxy ëª¨ë“œ í™•ì¸
kubectl get configmap -n kube-system kube-proxy -o yaml | grep mode

# 2. iptables ê·œì¹™ í™•ì¸
sudo iptables -t nat -L -n | grep KUBE

# 3. IPVS ê·œì¹™ í™•ì¸ (IPVS ëª¨ë“œì¸ ê²½ìš°)
sudo ipvsadm -Ln

# 4. kube-proxy ë©”íŠ¸ë¦­
kubectl port-forward -n kube-system pods/kube-proxy-xxxxx 10249:10249
curl localhost:10249/metrics
```

### ì‹¤ìŠµ 4: API Server ìš”ì²­ ì¶”ì 

```bash
# 1. API Server ê°ì‚¬ ë¡œê·¸ í™œì„±í™”
cat <<EOF > audit-policy.yaml
apiVersion: audit.k8s.io/v1
kind: Policy
rules:
- level: RequestResponse
  omitStages:
  - RequestReceived
  resources:
  - group: ""
    resources: ["pods", "services"]
  namespaces: ["default"]
EOF

# 2. API Server ì¸ìˆ˜ì— ê°ì‚¬ ì„¤ì • ì¶”ê°€
--audit-policy-file=/etc/kubernetes/audit-policy.yaml
--audit-log-path=/var/log/kubernetes/audit.log
--audit-log-maxage=30
--audit-log-maxbackup=10
--audit-log-maxsize=100

# 3. ê°ì‚¬ ë¡œê·¸ í™•ì¸
tail -f /var/log/kubernetes/audit.log | jq .
```

---

## ğŸ“ í•µì‹¬ ê°œë… ì •ë¦¬

### ì•„í‚¤í…ì²˜ ì´í•´ë„ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Control Planeì˜ 5ê°€ì§€ ì£¼ìš” ì»´í¬ë„ŒíŠ¸ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤
- [ ] Pod ìƒì„± ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤
- [ ] etcdì˜ ì—­í• ê³¼ ì¤‘ìš”ì„±ì„ ì´í•´í•œë‹¤
- [ ] Schedulerì˜ Pod ë°°ì¹˜ ê²°ì • ê³¼ì •ì„ ì•ˆë‹¤
- [ ] Controllerì˜ ì¡°ì • ë£¨í”„(Reconciliation Loop)ë¥¼ ì´í•´í•œë‹¤
- [ ] kubeletê³¼ Container Runtimeì˜ ê´€ê³„ë¥¼ ì•ˆë‹¤
- [ ] kube-proxyì˜ 3ê°€ì§€ ëª¨ë“œ ì°¨ì´ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆë‹¤
- [ ] HA êµ¬ì„±ì˜ í•„ìš”ì„±ê³¼ ë°©ë²•ì„ ì´í•´í•œë‹¤

### ğŸš€ ì‹¬í™” í•™ìŠµ ì£¼ì œ

1. **Custom Controller ê°œë°œ**: client-go ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©
2. **Admission Webhook**: ValidatingWebhook, MutatingWebhook
3. **CRI êµ¬í˜„ì²´ ë¹„êµ**: containerd vs CRI-O
4. **etcd ì„±ëŠ¥ íŠœë‹**: ëŒ€ê·œëª¨ í´ëŸ¬ìŠ¤í„° ìš´ì˜
5. **Federation**: ë©€í‹° í´ëŸ¬ìŠ¤í„° ê´€ë¦¬

---

## ğŸ’¡ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ

### ì¼ë°˜ì ì¸ ë¬¸ì œì™€ í•´ê²°

| ì¦ìƒ | ê°€ëŠ¥í•œ ì›ì¸ | í•´ê²° ë°©ë²• |
|-----|-----------|----------|
| kubectl ëª…ë ¹ ì‘ë‹µ ì—†ìŒ | API Server ë¬¸ì œ | API Server ë¡œê·¸ í™•ì¸, ì¸ì¦ì„œ ë§Œë£Œ í™•ì¸ |
| Pod Pending ìƒíƒœ | ë¦¬ì†ŒìŠ¤ ë¶€ì¡±, ìŠ¤ì¼€ì¤„ë§ ì‹¤íŒ¨ | Node ë¦¬ì†ŒìŠ¤ í™•ì¸, Pod ìš”êµ¬ì‚¬í•­ í™•ì¸ |
| Node NotReady | kubelet ë¬¸ì œ, ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ | kubelet ë¡œê·¸ í™•ì¸, CNI í”ŒëŸ¬ê·¸ì¸ í™•ì¸ |
| Service ì ‘ì† ë¶ˆê°€ | Endpoint ì—†ìŒ, kube-proxy ë¬¸ì œ | Endpoint í™•ì¸, iptables ê·œì¹™ í™•ì¸ |

---

> ğŸš€ **ë‹¤ìŒ ë¬¸ì„œ**: [first-deployment.md](first-deployment.md)ì—ì„œ ì‹¤ì œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë°°í¬í•´ë³´ì„¸ìš”!