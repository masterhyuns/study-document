# ğŸ“Š Kubernetes ëª¨ë‹ˆí„°ë§ ì™„ë²½ êµ¬ì¶• ê°€ì´ë“œ

> ğŸ’¡ **ëª©í‘œ**: Prometheusì™€ Grafanaë¥¼ í™œìš©í•˜ì—¬ í”„ë¡œë•ì…˜ê¸‰ Kubernetes ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ê³  ìš´ì˜í•©ë‹ˆë‹¤.

## ğŸ“š ëª©ì°¨

1. [**ëª¨ë‹ˆí„°ë§ ì•„í‚¤í…ì²˜**](#ëª¨ë‹ˆí„°ë§-ì•„í‚¤í…ì²˜)
2. [**Prometheus êµ¬ì¶•**](#prometheus-êµ¬ì¶•)
3. [**Grafana ëŒ€ì‹œë³´ë“œ**](#grafana-ëŒ€ì‹œë³´ë“œ)
4. [**ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì „ëµ**](#ë©”íŠ¸ë¦­-ìˆ˜ì§‘-ì „ëµ)
5. [**ì•Œë¦¼ ì„¤ì •**](#ì•Œë¦¼-ì„¤ì •)
6. [**ì‹¤ì „ ëª¨ë‹ˆí„°ë§ ì‹œë‚˜ë¦¬ì˜¤**](#ì‹¤ì „-ëª¨ë‹ˆí„°ë§-ì‹œë‚˜ë¦¬ì˜¤)
7. [**ì„±ëŠ¥ ìµœì í™”**](#ì„±ëŠ¥-ìµœì í™”)

---

## ğŸ—ï¸ ëª¨ë‹ˆí„°ë§ ì•„í‚¤í…ì²˜

### ì „ì²´ êµ¬ì„±ë„

```mermaid
graph TB
    subgraph "Kubernetes Cluster"
        subgraph "Monitoring Namespace"
            P[Prometheus Server] 
            AM[AlertManager]
            G[Grafana]
            PS[Prometheus Storage]
        end
        
        subgraph "Applications"
            A1[App Pod 1]
            A2[App Pod 2]
            A3[App Pod 3]
        end
        
        subgraph "System Components"
            KSM[kube-state-metrics]
            NE[node-exporter]
            CM[cAdvisor]
            CE[Custom Exporters]
        end
        
        subgraph "Service Mesh"
            I[Istio/Linkerd Metrics]
        end
    end
    
    P --> |Scrape| A1
    P --> |Scrape| A2
    P --> |Scrape| A3
    P --> |Scrape| KSM
    P --> |Scrape| NE
    P --> |Scrape| CM
    P --> |Scrape| CE
    P --> |Scrape| I
    
    P --> PS
    P --> AM
    G --> P
    
    AM --> |Alert| S[Slack]
    AM --> |Alert| PD[PagerDuty]
    AM --> |Alert| E[Email]
```

### í•µì‹¬ ì»´í¬ë„ŒíŠ¸

| ì»´í¬ë„ŒíŠ¸ | ì—­í•  | ìˆ˜ì§‘ ë©”íŠ¸ë¦­ |
|---------|------|------------|
| **Prometheus** | ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ì €ì¥ | ëª¨ë“  ë©”íŠ¸ë¦­ |
| **Grafana** | ì‹œê°í™” | - |
| **AlertManager** | ì•Œë¦¼ ê´€ë¦¬ | - |
| **kube-state-metrics** | K8s ì˜¤ë¸Œì íŠ¸ ìƒíƒœ | Deployment, Pod, Node ìƒíƒœ |
| **node-exporter** | ë…¸ë“œ ë©”íŠ¸ë¦­ | CPU, Memory, Disk, Network |
| **cAdvisor** | ì»¨í…Œì´ë„ˆ ë©”íŠ¸ë¦­ | ì»¨í…Œì´ë„ˆ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ |

---

## ğŸš€ Prometheus êµ¬ì¶•

### 1. Prometheus Operator ì„¤ì¹˜

```bash
# Helmìœ¼ë¡œ ì„¤ì¹˜ (ê¶Œì¥)
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# values.yaml ìƒì„±
cat <<EOF > prometheus-values.yaml
prometheus:
  prometheusSpec:
    retention: 30d
    retentionSize: "50GB"
    
    resources:
      requests:
        memory: 2Gi
        cpu: 1000m
      limits:
        memory: 4Gi
        cpu: 2000m
    
    storageSpec:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 100Gi
    
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    ruleSelectorNilUsesHelmValues: false

alertmanager:
  alertmanagerSpec:
    retention: 120h
    storage:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi

grafana:
  adminPassword: "admin123!"
  persistence:
    enabled: true
    size: 10Gi
  
  sidecar:
    dashboards:
      enabled: true
      provider:
        allowUiUpdates: true
    datasources:
      enabled: true

prometheusOperator:
  resources:
    limits:
      cpu: 200m
      memory: 200Mi
    requests:
      cpu: 100m
      memory: 100Mi

nodeExporter:
  enabled: true

kubeStateMetrics:
  enabled: true

kubelet:
  enabled: true
  serviceMonitor:
    metricRelabelings:
    - action: replace
      sourceLabels:
      - node
      targetLabel: instance
EOF

# ì„¤ì¹˜
helm install prometheus prometheus-community/kube-prometheus-stack \
  -f prometheus-values.yaml \
  --namespace monitoring \
  --create-namespace
```

### 2. Prometheus ì„¤ì •

```yaml
# prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
      external_labels:
        cluster: 'production'
        region: 'us-east-1'
    
    # Alerting ì„¤ì •
    alerting:
      alertmanagers:
      - static_configs:
        - targets:
          - alertmanager:9093
    
    # Rule íŒŒì¼ ë¡œë“œ
    rule_files:
      - "/etc/prometheus/rules/*.yml"
    
    # Scrape ì„¤ì •
    scrape_configs:
      # Kubernetes API Server
      - job_name: 'kubernetes-apiservers'
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
          action: keep
          regex: default;kubernetes;https
      
      # Kubernetes Nodes
      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
        - role: node
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
      
      # Kubernetes Pods
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
        - role: pod
        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          target_label: __address__
```

### 3. ServiceMonitor ì„¤ì •

```yaml
# ServiceMonitorë¡œ ì• í”Œë¦¬ì¼€ì´ì…˜ ëª¨ë‹ˆí„°ë§
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: app-metrics
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: my-app
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
    relabelings:
    - sourceLabels: [__meta_kubernetes_pod_name]
      targetLabel: pod
    - sourceLabels: [__meta_kubernetes_namespace]
      targetLabel: namespace
```

### 4. PodMonitor ì„¤ì •

```yaml
# PodMonitorë¡œ ì§ì ‘ Pod ëª¨ë‹ˆí„°ë§
apiVersion: monitoring.coreos.com/v1
kind: PodMonitor
metadata:
  name: app-pods
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: my-app
  podMetricsEndpoints:
  - port: metrics
    interval: 30s
    path: /metrics
```

---

## ğŸ“ˆ Grafana ëŒ€ì‹œë³´ë“œ

### 1. í•„ìˆ˜ ëŒ€ì‹œë³´ë“œ ì„¤ì¹˜

```bash
# ëŒ€ì‹œë³´ë“œ IDë¡œ import
# 1. Kubernetes Cluster Overview - 8685
# 2. Kubernetes Pods - 6417
# 3. Node Exporter Full - 1860
# 4. NGINX Ingress Controller - 9614
# 5. Kubernetes Deployment - 8349

# ConfigMapìœ¼ë¡œ ëŒ€ì‹œë³´ë“œ ìë™ í”„ë¡œë¹„ì €ë‹
cat <<EOF > grafana-dashboards.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboard-k8s-overview
  namespace: monitoring
  labels:
    grafana_dashboard: "1"
data:
  k8s-overview.json: |
    {
      "dashboard": {
        "title": "Kubernetes Overview",
        "panels": [
          {
            "title": "CPU Usage",
            "targets": [
              {
                "expr": "sum(rate(container_cpu_usage_seconds_total[5m])) by (pod)"
              }
            ]
          },
          {
            "title": "Memory Usage",
            "targets": [
              {
                "expr": "sum(container_memory_usage_bytes) by (pod)"
              }
            ]
          }
        ]
      }
    }
EOF
```

### 2. Custom Dashboard ìƒì„±

```json
{
  "dashboard": {
    "title": "Application Metrics",
    "templating": {
      "list": [
        {
          "name": "namespace",
          "type": "query",
          "query": "label_values(kube_pod_info, namespace)"
        },
        {
          "name": "pod",
          "type": "query",
          "query": "label_values(kube_pod_info{namespace=\"$namespace\"}, pod)"
        }
      ]
    },
    "panels": [
      {
        "title": "Request Rate",
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
        "targets": [
          {
            "expr": "sum(rate(http_requests_total{namespace=\"$namespace\"}[5m])) by (status)"
          }
        ]
      },
      {
        "title": "Response Time",
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
        "targets": [
          {
            "expr": "histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))"
          }
        ]
      },
      {
        "title": "Error Rate",
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8},
        "targets": [
          {
            "expr": "sum(rate(http_requests_total{status=~\"5..\"}[5m])) / sum(rate(http_requests_total[5m]))"
          }
        ]
      }
    ]
  }
}
```

### 3. ëŒ€ì‹œë³´ë“œ ìë™í™”

```yaml
# Dashboard as Code
apiVersion: integreatly.org/v1alpha1
kind: GrafanaDashboard
metadata:
  name: app-dashboard
  namespace: monitoring
spec:
  json: |
    {
      "dashboard": {
        "title": "Application Dashboard",
        "refresh": "10s",
        "time": {
          "from": "now-1h",
          "to": "now"
        },
        "panels": [...]
      }
    }
  datasources:
  - inputName: "DS_PROMETHEUS"
    datasourceName: "Prometheus"
```

---

## ğŸ“Š ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì „ëµ

### 1. ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”íŠ¸ë¦­

```go
// Go ì• í”Œë¦¬ì¼€ì´ì…˜ ì˜ˆì‹œ
package main

import (
    "net/http"
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promhttp"
)

var (
    httpRequestsTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "http_requests_total",
            Help: "Total number of HTTP requests",
        },
        []string{"method", "endpoint", "status"},
    )
    
    httpDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "http_request_duration_seconds",
            Help: "Duration of HTTP requests in seconds",
            Buckets: prometheus.DefBuckets,
        },
        []string{"method", "endpoint"},
    )
)

func init() {
    prometheus.MustRegister(httpRequestsTotal)
    prometheus.MustRegister(httpDuration)
}

func main() {
    http.Handle("/metrics", promhttp.Handler())
    http.ListenAndServe(":2112", nil)
}
```

```python
# Python ì• í”Œë¦¬ì¼€ì´ì…˜ ì˜ˆì‹œ
from prometheus_client import Counter, Histogram, generate_latest
from flask import Flask, Response

app = Flask(__name__)

REQUEST_COUNT = Counter(
    'app_requests_total', 
    'Total request count',
    ['method', 'endpoint', 'status']
)

REQUEST_LATENCY = Histogram(
    'app_request_latency_seconds',
    'Request latency',
    ['method', 'endpoint']
)

@app.route('/metrics')
def metrics():
    return Response(generate_latest(), mimetype='text/plain')

@app.route('/')
@REQUEST_LATENCY.time()
@REQUEST_COUNT.count_exceptions()
def index():
    return 'Hello World!'
```

### 2. Custom Metrics

```yaml
# HPA with Custom Metrics
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: app
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "100"
```

### 3. ë©”íŠ¸ë¦­ ë¶„ë¥˜

```yaml
# RED Method
- Rate: ìš”ì²­ ë¹„ìœ¨
  expr: sum(rate(http_requests_total[5m]))
  
- Errors: ì˜¤ë¥˜ìœ¨
  expr: sum(rate(http_requests_total{status=~"5.."}[5m]))
  
- Duration: ì‘ë‹µ ì‹œê°„
  expr: histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))

# USE Method
- Utilization: ì‚¬ìš©ë¥ 
  expr: (1 - avg(irate(node_cpu_seconds_total{mode="idle"}[5m]))) * 100
  
- Saturation: í¬í™”ë„
  expr: node_load1 / count(node_cpu_seconds_total{mode="idle"}) by (instance)
  
- Errors: ì˜¤ë¥˜
  expr: rate(node_network_receive_errs_total[5m])
```

---

## ğŸš¨ ì•Œë¦¼ ì„¤ì •

### 1. PrometheusRule ì„¤ì •

```yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: app-alerts
  namespace: monitoring
spec:
  groups:
  - name: app.rules
    interval: 30s
    rules:
    # Pod ê´€ë ¨ ì•Œë¦¼
    - alert: PodCrashLooping
      expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
      for: 5m
      labels:
        severity: critical
        team: platform
      annotations:
        summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} crash looping"
        description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} has restarted {{ $value }} times in 15 minutes"
    
    # ë©”ëª¨ë¦¬ ì•Œë¦¼
    - alert: HighMemoryUsage
      expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) > 0.9
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High memory usage in {{ $labels.namespace }}/{{ $labels.pod }}"
        description: "Memory usage is above 90% (current: {{ $value | humanizePercentage }})"
    
    # CPU ì•Œë¦¼
    - alert: HighCPUUsage
      expr: (rate(container_cpu_usage_seconds_total[5m]) / container_spec_cpu_quota) > 0.8
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High CPU usage in {{ $labels.namespace }}/{{ $labels.pod }}"
    
    # ë””ìŠ¤í¬ ì•Œë¦¼
    - alert: DiskSpaceLow
      expr: (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) < 0.1
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "Low disk space on {{ $labels.instance }}"
    
    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì•Œë¦¼
    - alert: HighErrorRate
      expr: (sum(rate(http_requests_total{status=~"5.."}[5m])) / sum(rate(http_requests_total[5m]))) > 0.01
      for: 5m
      labels:
        severity: critical
        team: backend
      annotations:
        summary: "High error rate detected"
        description: "Error rate is {{ $value | humanizePercentage }}"
    
    - alert: SlowResponseTime
      expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le)) > 1
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Slow response time detected"
        description: "95th percentile response time is {{ $value }}s"
```

### 2. AlertManager ì„¤ì •

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: monitoring
data:
  alertmanager.yml: |
    global:
      resolve_timeout: 5m
      slack_api_url: 'YOUR_SLACK_WEBHOOK_URL'
    
    templates:
    - '/etc/alertmanager/templates/*.tmpl'
    
    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      receiver: 'default'
      
      routes:
      - match:
          severity: critical
        receiver: 'critical'
        continue: true
        
      - match:
          severity: warning
        receiver: 'warning'
        
      - match:
          team: platform
        receiver: 'platform-team'
    
    inhibit_rules:
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      equal: ['alertname', 'namespace']
    
    receivers:
    - name: 'default'
      slack_configs:
      - channel: '#alerts'
        title: 'Kubernetes Alert'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}\n{{ .Annotations.description }}{{ end }}'
    
    - name: 'critical'
      slack_configs:
      - channel: '#critical-alerts'
        title: 'ğŸš¨ CRITICAL Alert'
        color: 'danger'
      pagerduty_configs:
      - service_key: 'YOUR_PAGERDUTY_KEY'
      
    - name: 'warning'
      slack_configs:
      - channel: '#warnings'
        title: 'âš ï¸ Warning'
        color: 'warning'
    
    - name: 'platform-team'
      email_configs:
      - to: 'platform-team@example.com'
        from: 'alerts@example.com'
        smarthost: 'smtp.example.com:587'
        auth_username: 'alerts@example.com'
        auth_password: 'password'
```

### 3. ì•Œë¦¼ í…œí”Œë¦¿

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-templates
  namespace: monitoring
data:
  slack.tmpl: |
    {{ define "slack.title" }}
    [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .GroupLabels.SortedPairs.Values | join " " }}
    {{ end }}
    
    {{ define "slack.text" }}
    {{ range .Alerts }}
    *Alert:* {{ .Annotations.summary }}
    *Description:* {{ .Annotations.description }}
    *Severity:* {{ .Labels.severity }}
    *Details:*
    {{ range .Labels.SortedPairs }} â€¢ *{{ .Name }}:* `{{ .Value }}`
    {{ end }}
    {{ end }}
    {{ end }}
```

---

## ğŸ¯ ì‹¤ì „ ëª¨ë‹ˆí„°ë§ ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ì„±ëŠ¥ ì €í•˜ ê°ì§€

```yaml
# SLO ê¸°ë°˜ ëª¨ë‹ˆí„°ë§
- alert: SLOViolation
  expr: |
    (
      sum(rate(http_requests_total{status!~"5.."}[5m]))
      /
      sum(rate(http_requests_total[5m]))
    ) < 0.999
  for: 5m
  labels:
    severity: critical
  annotations:
    summary: "SLO violation: availability below 99.9%"
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: ë¦¬ì†ŒìŠ¤ ìµœì í™”

```promql
# ë¯¸ì‚¬ìš© ë¦¬ì†ŒìŠ¤ ì°¾ê¸°
# CPU ìš”ì²­ ëŒ€ë¹„ ì‹¤ì œ ì‚¬ìš©ë¥ 
(sum by (namespace, pod) (rate(container_cpu_usage_seconds_total[5m]))) 
/ 
(sum by (namespace, pod) (container_spec_cpu_quota)) < 0.1

# ë©”ëª¨ë¦¬ ìš”ì²­ ëŒ€ë¹„ ì‹¤ì œ ì‚¬ìš©ë¥ 
(sum by (namespace, pod) (container_memory_usage_bytes)) 
/ 
(sum by (namespace, pod) (container_spec_memory_limit_bytes)) < 0.1
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: ë¹„ìš© ìµœì í™”

```yaml
# ë¹„ìš© ê´€ë ¨ ë©”íŠ¸ë¦­
- record: namespace:cpu:cost_per_hour
  expr: |
    sum by (namespace) (
      rate(container_cpu_usage_seconds_total[1h]) * 0.032
    )
    
- record: namespace:memory:cost_per_hour
  expr: |
    sum by (namespace) (
      container_memory_usage_bytes / 1024 / 1024 / 1024 * 0.004
    )
```

---

## âš¡ ì„±ëŠ¥ ìµœì í™”

### 1. Prometheus ìµœì í™”

```yaml
# ìŠ¤í† ë¦¬ì§€ ì„¤ì •
storage:
  tsdb:
    retention.time: 15d
    retention.size: 50GB
    wal-compression: true
    
# ì¿¼ë¦¬ ìµœì í™”
query:
  max-samples: 50000000
  timeout: 2m
  max-concurrency: 20
  
# ë©”ëª¨ë¦¬ ìµœì í™”
limits:
  memory: 4Gi
```

### 2. ë ˆì½”ë”© ë£° í™œìš©

```yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: recording-rules
spec:
  groups:
  - name: cpu_recording
    interval: 30s
    rules:
    - record: instance:node_cpu_utilisation:rate5m
      expr: |
        1 - avg by (instance) (
          rate(node_cpu_seconds_total{mode="idle"}[5m])
        )
    
    - record: namespace:container_cpu:sum_rate
      expr: |
        sum by (namespace) (
          rate(container_cpu_usage_seconds_total[5m])
        )
```

### 3. ì¹´ë””ë„ë¦¬í‹° ê´€ë¦¬

```promql
# ë†’ì€ ì¹´ë””ë„ë¦¬í‹° ë©”íŠ¸ë¦­ ì°¾ê¸°
topk(10, count by (__name__)({__name__=~".+"}))

# ë ˆì´ë¸” ì¹´ë””ë„ë¦¬í‹° í™•ì¸
count(count by (label_name) (metric_name))
```

---

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ í•´ê²° ì²´í¬ë¦¬ìŠ¤íŠ¸

```bash
# 1. Prometheus ìƒíƒœ í™•ì¸
kubectl get pods -n monitoring
kubectl logs -n monitoring prometheus-server-0

# 2. íƒ€ê²Ÿ ìƒíƒœ í™•ì¸
curl http://prometheus:9090/api/v1/targets

# 3. ë©”íŠ¸ë¦­ ìˆ˜ì§‘ í™•ì¸
curl http://prometheus:9090/api/v1/query?query=up

# 4. Grafana ì—°ê²° í™•ì¸
kubectl logs -n monitoring grafana-xxx

# 5. AlertManager ìƒíƒœ
curl http://alertmanager:9093/api/v1/status
```

---

> ğŸš€ **ë‹¤ìŒ ë¬¸ì„œ**: [logging.md](logging.md)ì—ì„œ EFK Stackì„ í™œìš©í•œ ë¡œê¹… ì‹œìŠ¤í…œ êµ¬ì¶•ì„ ì•Œì•„ë³´ì„¸ìš”!