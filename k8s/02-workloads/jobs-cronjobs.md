# âš¡ Jobs & CronJobs ì™„ë²½ ê°€ì´ë“œ

> ğŸ’¡ **ëª©í‘œ**: Kubernetesì—ì„œ ë°°ì¹˜ ì‘ì—…ê³¼ ì •ê¸° ì‘ì—…ì„ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê³ , Jobê³¼ CronJobì˜ ê³ ê¸‰ ê¸°ëŠ¥ì„ ë§ˆìŠ¤í„°í•©ë‹ˆë‹¤.

## ğŸ“š ëª©ì°¨

1. [**Job ê°œë…ê³¼ íŒ¨í„´**](#job-ê°œë…ê³¼-íŒ¨í„´)
2. [**Job ë³‘ë ¬ ì²˜ë¦¬**](#job-ë³‘ë ¬-ì²˜ë¦¬)
3. [**CronJob ìŠ¤ì¼€ì¤„ë§**](#cronjob-ìŠ¤ì¼€ì¤„ë§)
4. [**ì‹¤ì „ ì‹œë‚˜ë¦¬ì˜¤**](#ì‹¤ì „-ì‹œë‚˜ë¦¬ì˜¤)
5. [**Job ëª¨ë‹ˆí„°ë§ê³¼ ë””ë²„ê¹…**](#job-ëª¨ë‹ˆí„°ë§ê³¼-ë””ë²„ê¹…)
6. [**ê³ ê¸‰ íŒ¨í„´**](#ê³ ê¸‰-íŒ¨í„´)
7. [**Best Practices**](#best-practices)

---

## ğŸ¯ Job ê°œë…ê³¼ íŒ¨í„´

### Jobì´ë€?

```mermaid
graph LR
    subgraph "Job Lifecycle"
        J[Job Created] --> P1[Pod 1 Running]
        J --> P2[Pod 2 Running]
        J --> P3[Pod 3 Running]
        
        P1 --> S1[Success]
        P2 --> F1[Failed] --> R1[Retry]
        P3 --> S2[Success]
        
        R1 --> S3[Success]
        
        S1 --> C[Job Complete]
        S2 --> C
        S3 --> C
    end
```

### ê¸°ë³¸ Job ì •ì˜

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: simple-job
spec:
  # Job ì™„ë£Œ ì¡°ê±´
  completions: 1          # ì„±ê³µí•´ì•¼ í•  Pod ìˆ˜
  parallelism: 1          # ë™ì‹œ ì‹¤í–‰ Pod ìˆ˜
  backoffLimit: 6         # ì¬ì‹œë„ íšŸìˆ˜
  activeDeadlineSeconds: 3600  # Job ì „ì²´ íƒ€ì„ì•„ì›ƒ
  ttlSecondsAfterFinished: 100  # ì™„ë£Œ í›„ ìë™ ì‚­ì œ (ì´ˆ)
  
  template:
    metadata:
      labels:
        app: batch-job
    spec:
      restartPolicy: OnFailure  # Never ë˜ëŠ” OnFailure
      containers:
      - name: worker
        image: busybox
        command: ['sh', '-c']
        args:
        - |
          echo "Starting job..."
          sleep 10
          echo "Job completed!"
          exit 0
```

### Job íŒ¨í„´ ë¹„êµ

| íŒ¨í„´ | completions | parallelism | ì‚¬ìš© ì‚¬ë¡€ |
|------|------------|-------------|-----------|
| **ë‹¨ì¼ ì‘ì—…** | 1 | 1 | ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ |
| **ê³ ì • ì™„ë£Œ ìˆ˜** | N | M | ë°°ì¹˜ ì²˜ë¦¬ |
| **ì‘ì—… í** | 1 | N | ë©”ì‹œì§€ ì²˜ë¦¬ |
| **ë³‘ë ¬ ì²˜ë¦¬** | N | N | ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ |

---

## ğŸš€ Job ë³‘ë ¬ ì²˜ë¦¬

### ë³‘ë ¬ ì²˜ë¦¬ íŒ¨í„´

```yaml
# íŒ¨í„´ 1: ê³ ì • ì™„ë£Œ ìˆ˜ ë³‘ë ¬ ì²˜ë¦¬
apiVersion: batch/v1
kind: Job
metadata:
  name: parallel-job
spec:
  completions: 10    # ì´ 10ê°œ ì‘ì—… ì™„ë£Œ í•„ìš”
  parallelism: 3     # ë™ì‹œì— 3ê°œì”© ì‹¤í–‰
  
  template:
    spec:
      restartPolicy: OnFailure
      containers:
      - name: worker
        image: busybox
        command: ['sh', '-c']
        args:
        - |
          # JOB_COMPLETION_INDEX í™œìš© (1.21+)
          echo "Processing batch $JOB_COMPLETION_INDEX"
          sleep $((RANDOM % 10 + 1))
          echo "Batch $JOB_COMPLETION_INDEX completed"

---
# íŒ¨í„´ 2: Work Queue íŒ¨í„´
apiVersion: batch/v1
kind: Job
metadata:
  name: work-queue-job
spec:
  parallelism: 5     # 5ê°œ ì›Œì»¤ ë™ì‹œ ì‹¤í–‰
  completions: null  # ì›Œì»¤ê°€ ëª¨ë‘ ì„±ê³µí•˜ë©´ ì™„ë£Œ
  
  template:
    spec:
      restartPolicy: OnFailure
      containers:
      - name: worker
        image: myapp:worker
        env:
        - name: QUEUE_URL
          value: "redis://redis-service:6379"
        command: ['python']
        args:
        - -c
        - |
          import redis
          import time
          
          r = redis.from_url(os.environ['QUEUE_URL'])
          
          while True:
              job = r.blpop('job_queue', timeout=30)
              if not job:
                  break  # íê°€ ë¹„ë©´ ì¢…ë£Œ
              
              process_job(job[1])
              print(f"Processed: {job[1]}")
```

### Indexed Job (1.21+)

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: indexed-job
spec:
  completions: 5
  parallelism: 3
  completionMode: Indexed  # ì¸ë±ìŠ¤ ëª¨ë“œ
  
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: worker
        image: busybox
        command: ['sh', '-c']
        args:
        - |
          echo "My index is: $JOB_COMPLETION_INDEX"
          
          # ì¸ë±ìŠ¤ë³„ ë‹¤ë¥¸ ì‘ì—… ìˆ˜í–‰
          case $JOB_COMPLETION_INDEX in
            0) echo "Processing dataset A";;
            1) echo "Processing dataset B";;
            2) echo "Processing dataset C";;
            3) echo "Processing dataset D";;
            4) echo "Processing dataset E";;
          esac
          
          sleep 10
          echo "Index $JOB_COMPLETION_INDEX completed"
```

### ë™ì  ë³‘ë ¬ ì²˜ë¦¬

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: dynamic-parallel-job
spec:
  parallelism: 10
  completions: 100
  
  template:
    spec:
      restartPolicy: OnFailure
      initContainers:
      # ì‘ì—… ë¶„í• 
      - name: job-splitter
        image: busybox
        command: ['sh', '-c']
        args:
        - |
          # ì „ì²´ ì‘ì—…ì„ ì²­í¬ë¡œ ë¶„í• 
          TOTAL_ITEMS=1000000
          CHUNK_SIZE=$((TOTAL_ITEMS / 100))
          START=$((JOB_COMPLETION_INDEX * CHUNK_SIZE))
          END=$((START + CHUNK_SIZE))
          
          echo "START=$START" > /config/range
          echo "END=$END" >> /config/range
        volumeMounts:
        - name: config
          mountPath: /config
      
      containers:
      - name: processor
        image: myapp:processor
        command: ['sh', '-c']
        args:
        - |
          source /config/range
          echo "Processing items from $START to $END"
          
          # ì‹¤ì œ ì²˜ë¦¬ ë¡œì§
          process_batch --start=$START --end=$END
        volumeMounts:
        - name: config
          mountPath: /config
      
      volumes:
      - name: config
        emptyDir: {}
```

---

## ğŸ“… CronJob ìŠ¤ì¼€ì¤„ë§

### CronJob ê¸°ë³¸

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: backup-cronjob
spec:
  schedule: "0 2 * * *"  # ë§¤ì¼ ìƒˆë²½ 2ì‹œ
  
  # Job ì„¤ì •
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  startingDeadlineSeconds: 200  # ëŠ¦ì€ ì‹œì‘ í—ˆìš© ì‹œê°„
  concurrencyPolicy: Forbid     # ë™ì‹œ ì‹¤í–‰ ì •ì±…
  
  jobTemplate:
    spec:
      backoffLimit: 3
      ttlSecondsAfterFinished: 3600
      
      template:
        spec:
          restartPolicy: OnFailure
          containers:
          - name: backup
            image: backup-tool:latest
            command: ['/bin/bash']
            args:
            - -c
            - |
              DATE=$(date +%Y%m%d_%H%M%S)
              echo "Starting backup at $DATE"
              
              # ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
              mysqldump -h mysql-service -u root -p$MYSQL_PASSWORD \
                --all-databases > /backup/db_$DATE.sql
              
              # S3 ì—…ë¡œë“œ
              aws s3 cp /backup/db_$DATE.sql s3://my-backup-bucket/
              
              echo "Backup completed"
            
            env:
            - name: MYSQL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mysql-secret
                  key: password
            
            volumeMounts:
            - name: backup
              mountPath: /backup
          
          volumes:
          - name: backup
            emptyDir: {}
```

### Cron ìŠ¤ì¼€ì¤„ ë¬¸ë²•

```yaml
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë¶„ (0 - 59)
# â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‹œ (0 - 23)
# â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì¼ (1 - 31)
# â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì›” (1 - 12)
# â”‚ â”‚ â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìš”ì¼ (0 - 6) (ì¼ìš”ì¼ = 0 ë˜ëŠ” 7)
# â”‚ â”‚ â”‚ â”‚ â”‚
# * * * * *

# ì˜ˆì œ:
schedule: "*/5 * * * *"      # 5ë¶„ë§ˆë‹¤
schedule: "0 * * * *"        # ë§¤ì‹œê°„ ì •ê°
schedule: "0 0 * * *"        # ë§¤ì¼ ìì •
schedule: "0 0 * * 0"        # ë§¤ì£¼ ì¼ìš”ì¼ ìì •
schedule: "0 0 1 * *"        # ë§¤ì›” 1ì¼ ìì •
schedule: "0 0 1 1 *"        # ë§¤ë…„ 1ì›” 1ì¼
schedule: "30 2 * * 1-5"     # í‰ì¼ 2:30 AM
schedule: "0 */6 * * *"      # 6ì‹œê°„ë§ˆë‹¤
schedule: "@hourly"          # ë§¤ì‹œê°„ (0 * * * *)
schedule: "@daily"           # ë§¤ì¼ (0 0 * * *)
schedule: "@weekly"          # ë§¤ì£¼ (0 0 * * 0)
schedule: "@monthly"         # ë§¤ì›” (0 0 1 * *)
schedule: "@yearly"          # ë§¤ë…„ (0 0 1 1 *)
```

### Concurrency Policy

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: concurrent-cronjob
spec:
  schedule: "*/1 * * * *"
  
  # Allow: ë™ì‹œ ì‹¤í–‰ í—ˆìš© (ê¸°ë³¸ê°’)
  # Forbid: ì´ì „ Jobì´ ì‹¤í–‰ ì¤‘ì´ë©´ ê±´ë„ˆë›°ê¸°
  # Replace: ì´ì „ Jobì„ ì·¨ì†Œí•˜ê³  ìƒˆë¡œ ì‹œì‘
  concurrencyPolicy: Forbid
  
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
          - name: long-running
            image: busybox
            command: ['sh', '-c', 'echo "Running for 90 seconds"; sleep 90']
```

---

## ğŸ’¼ ì‹¤ì „ ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: db-migration
  annotations:
    "helm.sh/hook": pre-upgrade
    "helm.sh/hook-weight": "-5"
spec:
  backoffLimit: 1
  
  template:
    spec:
      restartPolicy: Never
      initContainers:
      # ë°ì´í„°ë² ì´ìŠ¤ ëŒ€ê¸°
      - name: wait-for-db
        image: busybox
        command: ['sh', '-c']
        args:
        - |
          until nc -z postgres-service 5432; do
            echo "Waiting for database..."
            sleep 2
          done
      
      containers:
      - name: migrate
        image: migrate/migrate:latest
        command: ['migrate']
        args:
        - -path=/migrations
        - -database=postgres://$(DB_USER):$(DB_PASS)@postgres-service/mydb?sslmode=disable
        - up
        
        env:
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: username
        - name: DB_PASS
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: password
        
        volumeMounts:
        - name: migrations
          mountPath: /migrations
      
      volumes:
      - name: migrations
        configMap:
          name: db-migrations
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: ETL íŒŒì´í”„ë¼ì¸

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: etl-pipeline
spec:
  schedule: "0 1 * * *"  # ë§¤ì¼ ìƒˆë²½ 1ì‹œ
  
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          
          # ETL ë‹¨ê³„ë³„ ì»¨í…Œì´ë„ˆ
          initContainers:
          # Extract
          - name: extract
            image: etl:extractor
            command: ['python', 'extract.py']
            env:
            - name: SOURCE_DB_URL
              value: "mysql://source-db:3306/data"
            volumeMounts:
            - name: data
              mountPath: /tmp/data
          
          # Transform
          - name: transform
            image: etl:transformer
            command: ['python', 'transform.py']
            volumeMounts:
            - name: data
              mountPath: /tmp/data
          
          # Load
          containers:
          - name: load
            image: etl:loader
            command: ['python', 'load.py']
            env:
            - name: TARGET_DB_URL
              value: "postgres://target-db:5432/warehouse"
            volumeMounts:
            - name: data
              mountPath: /tmp/data
            
            # ì™„ë£Œ ì•Œë¦¼
            lifecycle:
              postStart:
                exec:
                  command:
                  - /bin/sh
                  - -c
                  - |
                    curl -X POST https://hooks.slack.com/services/XXX \
                      -H 'Content-Type: application/json' \
                      -d '{"text":"ETL Pipeline started"}'
          
          volumes:
          - name: data
            emptyDir: {}
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: ë¡œê·¸ ì •ë¦¬ ë° ì•„ì¹´ì´ë¹™

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: log-cleanup
spec:
  schedule: "0 3 * * 0"  # ë§¤ì£¼ ì¼ìš”ì¼ ìƒˆë²½ 3ì‹œ
  
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
          - name: cleanup
            image: busybox
            command: ['/bin/sh']
            args:
            - -c
            - |
              echo "Starting log cleanup..."
              
              # 7ì¼ ì´ìƒ ëœ ë¡œê·¸ ì•„ì¹´ì´ë¹™
              find /logs -name "*.log" -mtime +7 -exec tar -czf {}.tar.gz {} \;
              find /logs -name "*.log" -mtime +7 -delete
              
              # 30ì¼ ì´ìƒ ëœ ì•„ì¹´ì´ë¸Œ ì‚­ì œ
              find /logs -name "*.tar.gz" -mtime +30 -delete
              
              # S3ë¡œ ì•„ì¹´ì´ë¸Œ ì—…ë¡œë“œ
              aws s3 sync /logs s3://log-archive/ --exclude "*.log"
              
              echo "Cleanup completed"
            
            volumeMounts:
            - name: logs
              mountPath: /logs
          
          volumes:
          - name: logs
            persistentVolumeClaim:
              claimName: logs-pvc
```

### ì‹œë‚˜ë¦¬ì˜¤ 4: ë°°ì¹˜ ì´ë¯¸ì§€ ì²˜ë¦¬

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: image-processing
spec:
  completions: 100
  parallelism: 10
  completionMode: Indexed
  
  template:
    spec:
      restartPolicy: OnFailure
      containers:
      - name: processor
        image: image-processor:latest
        command: ['python']
        args:
        - -c
        - |
          import os
          import boto3
          from PIL import Image
          
          # S3 í´ë¼ì´ì–¸íŠ¸
          s3 = boto3.client('s3')
          
          # ì‘ì—… ì¸ë±ìŠ¤ë¡œ ì²˜ë¦¬í•  ì´ë¯¸ì§€ ê²°ì •
          index = int(os.environ['JOB_COMPLETION_INDEX'])
          bucket = 'raw-images'
          
          # ì´ë¯¸ì§€ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
          response = s3.list_objects_v2(
              Bucket=bucket,
              MaxKeys=1,
              StartAfter=f'image_{index:04d}.jpg'
          )
          
          if 'Contents' in response:
              key = response['Contents'][0]['Key']
              
              # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
              s3.download_file(bucket, key, '/tmp/input.jpg')
              
              # ì´ë¯¸ì§€ ì²˜ë¦¬
              img = Image.open('/tmp/input.jpg')
              
              # ì¸ë„¤ì¼ ìƒì„±
              img.thumbnail((128, 128))
              img.save('/tmp/thumb.jpg')
              
              # ë¦¬ì‚¬ì´ì¦ˆ
              img = img.resize((800, 600))
              img.save('/tmp/resized.jpg')
              
              # ì—…ë¡œë“œ
              s3.upload_file('/tmp/thumb.jpg', 'thumbnails', key)
              s3.upload_file('/tmp/resized.jpg', 'processed', key)
              
              print(f"Processed {key}")
        
        env:
        - name: AWS_REGION
          value: us-west-2
        
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1"
```

### ì‹œë‚˜ë¦¬ì˜¤ 5: ì¸ì¦ì„œ ê°±ì‹ 

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cert-renewal
spec:
  schedule: "0 0 1 * *"  # ë§¤ì›” 1ì¼
  
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: cert-manager
          restartPolicy: OnFailure
          
          containers:
          - name: renew
            image: certbot/certbot:latest
            command: ['/bin/sh']
            args:
            - -c
            - |
              # Let's Encrypt ì¸ì¦ì„œ ê°±ì‹ 
              certbot renew \
                --non-interactive \
                --agree-tos \
                --email admin@example.com
              
              # Kubernetes Secret ì—…ë°ì´íŠ¸
              kubectl create secret tls web-tls \
                --cert=/etc/letsencrypt/live/example.com/fullchain.pem \
                --key=/etc/letsencrypt/live/example.com/privkey.pem \
                --dry-run=client -o yaml | kubectl apply -f -
              
              # Deployment ì¬ì‹œì‘ìœ¼ë¡œ ìƒˆ ì¸ì¦ì„œ ì ìš©
              kubectl rollout restart deployment/web-server
            
            volumeMounts:
            - name: certs
              mountPath: /etc/letsencrypt
          
          volumes:
          - name: certs
            persistentVolumeClaim:
              claimName: letsencrypt-pvc
```

---

## ğŸ“Š Job ëª¨ë‹ˆí„°ë§ê³¼ ë””ë²„ê¹…

### Job ìƒíƒœ í™•ì¸

```bash
# Job ëª©ë¡ ë° ìƒíƒœ
kubectl get jobs
kubectl describe job my-job

# Jobì˜ Pod í™•ì¸
kubectl get pods --selector=job-name=my-job

# Job ì´ë²¤íŠ¸ í™•ì¸
kubectl get events --field-selector involvedObject.name=my-job

# Job ë¡œê·¸ í™•ì¸
kubectl logs job/my-job
kubectl logs job/my-job --all-containers=true
kubectl logs job/my-job --previous

# CronJob ìƒíƒœ
kubectl get cronjobs
kubectl get jobs --selector=parent=my-cronjob
```

### Prometheus ë©”íŠ¸ë¦­

```yaml
apiVersion: v1
kind: ServiceMonitor
metadata:
  name: job-metrics
spec:
  selector:
    matchLabels:
      app: batch-job
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics

---
# Job í…œí”Œë¦¿ì— ë©”íŠ¸ë¦­ ì¶”ê°€
spec:
  template:
    spec:
      containers:
      - name: worker
        image: myapp:latest
        ports:
        - name: metrics
          containerPort: 9090
        env:
        - name: ENABLE_METRICS
          value: "true"
```

### ë””ë²„ê¹… Job

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: debug-job
spec:
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: debug
        image: nicolaka/netshoot
        command: ['sh', '-c']
        args:
        - |
          # ë””ë²„ê¹… ì •ë³´ ìˆ˜ì§‘
          echo "=== Environment ==="
          env | sort
          
          echo "=== Network ==="
          ip addr
          nslookup kubernetes.default
          
          echo "=== Disk ==="
          df -h
          
          echo "=== Memory ==="
          free -h
          
          echo "=== CPU ==="
          nproc
          
          # ì‹¤ì œ ì‘ì—…
          echo "Starting actual job..."
          # ...
```

---

## ğŸ¯ ê³ ê¸‰ íŒ¨í„´

### 1. Job ì²´ì´ë‹

```yaml
# Step 1: ë°ì´í„° ì¤€ë¹„
apiVersion: batch/v1
kind: Job
metadata:
  name: prepare-data
spec:
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: prepare
        image: busybox
        command: ['sh', '-c', 'echo "Preparing data..." && sleep 10']

---
# Step 2: ë°ì´í„° ì²˜ë¦¬ (Step 1 ì™„ë£Œ í›„ ì‹œì‘)
apiVersion: batch/v1
kind: Job
metadata:
  name: process-data
spec:
  template:
    spec:
      restartPolicy: Never
      initContainers:
      # ì´ì „ Job ì™„ë£Œ ëŒ€ê¸°
      - name: wait-prepare
        image: bitnami/kubectl
        command: ['sh', '-c']
        args:
        - |
          until kubectl get job prepare-data -o jsonpath='{.status.succeeded}' | grep -q "1"; do
            echo "Waiting for prepare-data job..."
            sleep 5
          done
      
      containers:
      - name: process
        image: busybox
        command: ['sh', '-c', 'echo "Processing data..." && sleep 10']
```

### 2. Sidecar Pattern Job

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: job-with-sidecar
spec:
  template:
    spec:
      restartPolicy: Never
      
      # ë©”ì¸ ì»¨í…Œì´ë„ˆì™€ ì‚¬ì´ë“œì¹´ ê³µìœ 
      shareProcessNamespace: true
      
      containers:
      # ë©”ì¸ ì‘ì—…
      - name: main
        image: myapp:latest
        command: ['python', 'process.py']
        volumeMounts:
        - name: shared
          mountPath: /data
      
      # ëª¨ë‹ˆí„°ë§ ì‚¬ì´ë“œì¹´
      - name: monitor
        image: monitoring:latest
        command: ['sh', '-c']
        args:
        - |
          while true; do
            if ! pgrep -f "process.py" > /dev/null; then
              echo "Main process completed"
              exit 0
            fi
            
            # ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            df -h /data
            ps aux | grep process.py
            
            sleep 10
          done
        volumeMounts:
        - name: shared
          mountPath: /data
      
      volumes:
      - name: shared
        emptyDir: {}
```

### 3. ì‹¤íŒ¨ ì²˜ë¦¬ íŒ¨í„´

```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: fault-tolerant-job
spec:
  backoffLimit: 5
  
  template:
    spec:
      restartPolicy: OnFailure
      
      containers:
      - name: worker
        image: myapp:latest
        command: ['sh', '-c']
        args:
        - |
          # ì¬ì‹œë„ ë¡œì§
          RETRY_COUNT=${RETRY_COUNT:-0}
          MAX_RETRIES=3
          
          echo "Attempt $((RETRY_COUNT + 1)) of $((MAX_RETRIES + 1))"
          
          # ì²´í¬í¬ì¸íŠ¸ ë³µêµ¬
          if [ -f /checkpoint/state ]; then
            echo "Resuming from checkpoint..."
            LAST_PROCESSED=$(cat /checkpoint/state)
          else
            LAST_PROCESSED=0
          fi
          
          # ì‘ì—… ìˆ˜í–‰
          for i in $(seq $((LAST_PROCESSED + 1)) 100); do
            echo "Processing item $i"
            
            # ëœë¤ ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜
            if [ $((RANDOM % 10)) -eq 0 ]; then
              echo "Error processing item $i"
              echo $((i - 1)) > /checkpoint/state
              exit 1
            fi
            
            echo $i > /checkpoint/state
            sleep 1
          done
          
          echo "Job completed successfully"
        
        env:
        - name: RETRY_COUNT
          value: "0"
        
        volumeMounts:
        - name: checkpoint
          mountPath: /checkpoint
      
      volumes:
      - name: checkpoint
        persistentVolumeClaim:
          claimName: checkpoint-pvc
```

---

## âœ… Best Practices

### 1. ë¦¬ì†ŒìŠ¤ ê´€ë¦¬

```yaml
spec:
  template:
    spec:
      containers:
      - name: worker
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "1Gi"
            cpu: "500m"
      
      # Job ì „ìš© ë…¸ë“œ ì‚¬ìš©
      nodeSelector:
        workload: batch
      
      # ë˜ëŠ” tolerations
      tolerations:
      - key: "batch"
        operator: "Equal"
        value: "true"
        effect: "NoSchedule"
```

### 2. íƒ€ì„ì•„ì›ƒ ì„¤ì •

```yaml
spec:
  # Job ë ˆë²¨ íƒ€ì„ì•„ì›ƒ
  activeDeadlineSeconds: 600
  
  template:
    spec:
      # Pod ë ˆë²¨ íƒ€ì„ì•„ì›ƒ
      activeDeadlineSeconds: 300
      
      containers:
      - name: worker
        # ì»¨í…Œì´ë„ˆ ë ˆë²¨ íƒ€ì„ì•„ì›ƒ
        livenessProbe:
          exec:
            command: ['cat', '/tmp/health']
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
```

### 3. ë©±ë“±ì„± ë³´ì¥

```yaml
spec:
  template:
    spec:
      containers:
      - name: idempotent-job
        command: ['sh', '-c']
        args:
        - |
          # ì‘ì—… ID ìƒì„±
          JOB_ID=$(echo $HOSTNAME | sha256sum | cut -c1-8)
          
          # ì´ë¯¸ ì²˜ë¦¬ëëŠ”ì§€ í™•ì¸
          if redis-cli -h redis EXISTS "job:$JOB_ID"; then
            echo "Job $JOB_ID already processed"
            exit 0
          fi
          
          # ì‘ì—… ìˆ˜í–‰
          process_job
          
          # ì™„ë£Œ í‘œì‹œ
          redis-cli -h redis SET "job:$JOB_ID" "completed" EX 86400
```

### 4. ë¡œê¹…ê³¼ ëª¨ë‹ˆí„°ë§

```yaml
spec:
  template:
    spec:
      containers:
      - name: worker
        env:
        # êµ¬ì¡°í™”ëœ ë¡œê¹…
        - name: LOG_FORMAT
          value: "json"
        - name: LOG_LEVEL
          value: "info"
        
        # ë©”íŠ¸ë¦­ ë…¸ì¶œ
        - name: ENABLE_METRICS
          value: "true"
        - name: METRICS_PORT
          value: "9090"
```

---

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Jobì´ ì™„ë£Œë˜ì§€ ì•ŠìŒ

```bash
# Pod ìƒíƒœ í™•ì¸
kubectl get pods -l job-name=my-job

# ì‹¤íŒ¨í•œ Pod ë¡œê·¸ í™•ì¸
kubectl logs -l job-name=my-job --tail=50

# Job ì´ë²¤íŠ¸ í™•ì¸
kubectl describe job my-job

# ê°•ì œ ì¢…ë£Œ
kubectl delete job my-job --cascade=foreground
```

### CronJobì´ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ

```bash
# CronJob ì¼ì‹œ ì¤‘ì§€ í™•ì¸
kubectl get cronjob my-cronjob -o jsonpath='{.spec.suspend}'

# ì¬í™œì„±í™”
kubectl patch cronjob my-cronjob -p '{"spec":{"suspend":false}}'

# ìˆ˜ë™ íŠ¸ë¦¬ê±°
kubectl create job --from=cronjob/my-cronjob manual-run
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±

```yaml
# OOMKilled ë°©ì§€
spec:
  template:
    spec:
      containers:
      - name: worker
        resources:
          requests:
            memory: "512Mi"
          limits:
            memory: "1Gi"
        env:
        # JVM ì•±ì˜ ê²½ìš°
        - name: JAVA_OPTS
          value: "-Xmx768m -Xms512m"
```

---

## ğŸ’¡ ê³ ê¸‰ íŒ

### 1. Job í…œí”Œë¦¿ ì¬ì‚¬ìš©

```bash
# CronJobì—ì„œ Job ìƒì„±
kubectl create job manual-backup --from=cronjob/backup-cronjob

# Job ë³µì œ
kubectl get job old-job -o yaml | \
  sed 's/name: old-job/name: new-job/' | \
  kubectl create -f -
```

### 2. ë™ì  Job ìƒì„±

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: job-generator
data:
  generate.sh: |
    #!/bin/bash
    for i in {1..10}; do
      cat <<EOF | kubectl apply -f -
    apiVersion: batch/v1
    kind: Job
    metadata:
      name: dynamic-job-$i
    spec:
      template:
        spec:
          restartPolicy: Never
          containers:
          - name: worker
            image: busybox
            command: ['echo', "Processing batch $i"]
    EOF
    done
```

### 3. Job ìš°ì„ ìˆœìœ„

```yaml
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: high-priority-batch
value: 1000

---
spec:
  template:
    spec:
      priorityClassName: high-priority-batch
```

---

> ğŸš€ Jobsì™€ CronJobsëŠ” Kubernetesì—ì„œ ë°°ì¹˜ ì‘ì—…ê³¼ ì •ê¸° ì‘ì—…ì„ ê´€ë¦¬í•˜ëŠ” ê°•ë ¥í•œ ë„êµ¬ì…ë‹ˆë‹¤!