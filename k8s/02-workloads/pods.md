# ğŸ¯ Kubernetes Pod ì™„ë²½ ê°€ì´ë“œ

> ğŸ’¡ **ëª©í‘œ**: Kubernetesì˜ ê°€ì¥ ì‘ì€ ë°°í¬ ë‹¨ìœ„ì¸ Podë¥¼ ê¹Šì´ ì´í•´í•˜ê³ , ë‹¤ì–‘í•œ íŒ¨í„´ê³¼ ê³ ê¸‰ ê¸°ëŠ¥ì„ í™œìš©í•©ë‹ˆë‹¤.

## ğŸ“š ëª©ì°¨

1. [**Pod ê°œë…ê³¼ êµ¬ì¡°**](#pod-ê°œë…ê³¼-êµ¬ì¡°)
2. [**Pod ìƒëª…ì£¼ê¸°**](#pod-ìƒëª…ì£¼ê¸°)
3. [**Multi-Container Patterns**](#multi-container-patterns)
4. [**Pod ë„¤íŠ¸ì›Œí‚¹ê³¼ ìŠ¤í† ë¦¬ì§€**](#pod-ë„¤íŠ¸ì›Œí‚¹ê³¼-ìŠ¤í† ë¦¬ì§€)
5. [**Pod ìŠ¤ì¼€ì¤„ë§**](#pod-ìŠ¤ì¼€ì¤„ë§)
6. [**Health Checks**](#health-checks)
7. [**Pod ë³´ì•ˆ**](#pod-ë³´ì•ˆ)
8. [**Best Practices**](#best-practices)

---

## ğŸ¯ Pod ê°œë…ê³¼ êµ¬ì¡°

### Podë€?

```mermaid
graph TB
    subgraph "Pod Structure"
        Pod[Pod - 192.168.1.10]
        Pod --> C1[Container 1<br/>nginx:latest<br/>Port: 80]
        Pod --> C2[Container 2<br/>app:v1.0<br/>Port: 8080]
        Pod --> V1[Volume:<br/>shared-data]
        C1 --> V1
        C2 --> V1
        
        subgraph "Shared Resources"
            Net[Network<br/>Namespace]
            IPC[IPC<br/>Namespace]
            UTS[UTS<br/>Namespace]
        end
        
        C1 --> Net
        C2 --> Net
        C1 --> IPC
        C2 --> IPC
    end
```

### ê¸°ë³¸ Pod ì •ì˜

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
  namespace: default
  labels:
    app: myapp
    tier: frontend
    version: v1
  annotations:
    description: "This is my application pod"
spec:
  containers:
  - name: main-app
    image: myapp:1.0
    ports:
    - containerPort: 8080
      name: http
      protocol: TCP
    env:
    - name: ENV_VAR
      value: "production"
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "500m"
```

### Pod vs Container

| íŠ¹ì„± | Pod | Container |
|-----|-----|-----------|
| **ì •ì˜** | ì»¨í…Œì´ë„ˆ ê·¸ë£¹ | ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ |
| **IP ì£¼ì†Œ** | í•˜ë‚˜ì˜ IP ê³µìœ  | Pod IP ì‚¬ìš© |
| **ì €ì¥ì†Œ** | Volume ê³µìœ  ê°€ëŠ¥ | ë…ë¦½ì  íŒŒì¼ì‹œìŠ¤í…œ |
| **ìƒëª…ì£¼ê¸°** | í•¨ê»˜ ì‹œì‘/ì¢…ë£Œ | ë…ë¦½ì  ì¬ì‹œì‘ ê°€ëŠ¥ |
| **í†µì‹ ** | localhostë¡œ í†µì‹  | ë„¤íŠ¸ì›Œí¬ í†µì‹  |

---

## ğŸ”„ Pod ìƒëª…ì£¼ê¸°

### Pod Phases

```mermaid
stateDiagram-v2
    [*] --> Pending: Pod ìƒì„±
    Pending --> Running: ìŠ¤ì¼€ì¤„ë§ & ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ
    Pending --> Failed: ìŠ¤ì¼€ì¤„ë§ ì‹¤íŒ¨
    Running --> Succeeded: ì •ìƒ ì¢…ë£Œ (Job)
    Running --> Failed: ë¹„ì •ìƒ ì¢…ë£Œ
    Running --> Unknown: ë…¸ë“œ ì—°ê²° ëŠê¹€
    Unknown --> Running: ì—°ê²° ë³µêµ¬
    Unknown --> Failed: Timeout
    Succeeded --> [*]
    Failed --> [*]
```

### Pod ìƒíƒœë³„ ì„¤ëª…

```yaml
# Pending ìƒíƒœ ì˜ˆì‹œ
apiVersion: v1
kind: Pod
metadata:
  name: pending-pod
spec:
  containers:
  - name: app
    image: nonexistent-image:latest  # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€
    
# kubectl describe pod pending-pod
# Events:
#   Warning  Failed     3s   kubelet  Failed to pull image

---
# Running ìƒíƒœ ì˜ˆì‹œ
apiVersion: v1
kind: Pod
metadata:
  name: running-pod
spec:
  containers:
  - name: app
    image: nginx
    livenessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 10

---
# Succeeded ìƒíƒœ (Job ì™„ë£Œ)
apiVersion: v1
kind: Pod
metadata:
  name: completed-pod
spec:
  restartPolicy: OnFailure
  containers:
  - name: job
    image: busybox
    command: ['sh', '-c', 'echo "Job completed" && exit 0']

---
# Failed ìƒíƒœ
apiVersion: v1
kind: Pod
metadata:
  name: failed-pod
spec:
  restartPolicy: Never
  containers:
  - name: app
    image: busybox
    command: ['sh', '-c', 'exit 1']
```

### Container States

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: container-states-demo
spec:
  containers:
  - name: main
    image: nginx
    lifecycle:
      postStart:
        exec:
          command: ["/bin/sh", "-c", "echo 'Container started' > /usr/share/message"]
      preStop:
        exec:
          command: ["/bin/sh", "-c", "nginx -s quit; while killall -0 nginx; do sleep 1; done"]
    
  # Container ìƒíƒœ í™•ì¸
  # kubectl get pod container-states-demo -o jsonpath='{.status.containerStatuses[0].state}'
  # Waiting / Running / Terminated
```

---

## ğŸ¨ Multi-Container Patterns

### 1. Sidecar Pattern

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: sidecar-pattern
spec:
  containers:
  # Main application
  - name: main-app
    image: myapp:1.0
    ports:
    - containerPort: 8080
    volumeMounts:
    - name: logs
      mountPath: /var/log/app
  
  # Sidecar: Log collector
  - name: log-collector
    image: fluentd
    volumeMounts:
    - name: logs
      mountPath: /var/log/app
    - name: fluentd-config
      mountPath: /fluentd/etc
  
  volumes:
  - name: logs
    emptyDir: {}
  - name: fluentd-config
    configMap:
      name: fluentd-config
```

### 2. Ambassador Pattern

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: ambassador-pattern
spec:
  containers:
  # Main application
  - name: main-app
    image: myapp:1.0
    env:
    - name: DB_HOST
      value: "localhost:6379"  # Ambassador proxy
  
  # Ambassador: Redis proxy
  - name: redis-ambassador
    image: redis-proxy
    ports:
    - containerPort: 6379
    env:
    - name: REDIS_SERVERS
      value: "redis-1:6379,redis-2:6379,redis-3:6379"
```

### 3. Adapter Pattern

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: adapter-pattern
spec:
  containers:
  # Legacy application with custom log format
  - name: legacy-app
    image: legacy-app:1.0
    volumeMounts:
    - name: logs
      mountPath: /var/log
  
  # Adapter: Convert logs to standard format
  - name: log-adapter
    image: log-transformer
    volumeMounts:
    - name: logs
      mountPath: /input
      readOnly: true
    - name: formatted-logs
      mountPath: /output
    command: ["/bin/sh"]
    args: 
    - -c
    - |
      tail -F /input/app.log | while read line; do
        echo "{\"timestamp\": \"$(date -Iseconds)\", \"message\": \"$line\"}" >> /output/app.json
      done
  
  volumes:
  - name: logs
    emptyDir: {}
  - name: formatted-logs
    emptyDir: {}
```

### 4. Init Container Pattern

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: init-container-pattern
spec:
  initContainers:
  # 1. ë°ì´í„°ë² ì´ìŠ¤ ëŒ€ê¸°
  - name: wait-for-db
    image: busybox:1.35
    command: ['sh', '-c']
    args:
    - |
      until nc -z postgres-service 5432; do
        echo "Waiting for database..."
        sleep 2
      done
      echo "Database is ready!"
  
  # 2. ì„¤ì • íŒŒì¼ ë‹¤ìš´ë¡œë“œ
  - name: fetch-config
    image: busybox:1.35
    command: ['sh', '-c']
    args:
    - |
      wget -O /config/app.conf https://config-server.com/app.conf
      echo "Config downloaded"
    volumeMounts:
    - name: config
      mountPath: /config
  
  # 3. ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜
  - name: migrate-db
    image: migrate/migrate
    command: ['migrate']
    args: ['-path', '/migrations', '-database', 'postgres://...', 'up']
    volumeMounts:
    - name: migrations
      mountPath: /migrations
  
  # Main containers
  containers:
  - name: main-app
    image: myapp:1.0
    volumeMounts:
    - name: config
      mountPath: /etc/app
      readOnly: true
  
  volumes:
  - name: config
    emptyDir: {}
  - name: migrations
    configMap:
      name: db-migrations
```

---

## ğŸŒ Pod ë„¤íŠ¸ì›Œí‚¹ê³¼ ìŠ¤í† ë¦¬ì§€

### Pod ë„¤íŠ¸ì›Œí‚¹

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: networking-demo
spec:
  hostNetwork: false  # í˜¸ìŠ¤íŠ¸ ë„¤íŠ¸ì›Œí¬ ì‚¬ìš© (ê¸°ë³¸ê°’: false)
  dnsPolicy: ClusterFirst  # DNS ì •ì±…
  hostname: my-pod  # Pod hostname
  subdomain: my-service  # FQDN: my-pod.my-service.default.svc.cluster.local
  
  hostAliases:  # /etc/hosts í•­ëª© ì¶”ê°€
  - ip: "127.0.0.1"
    hostnames:
    - "foo.local"
    - "bar.local"
  
  containers:
  - name: app
    image: nginx
    ports:
    - containerPort: 80
      name: http
      protocol: TCP
    - containerPort: 443
      name: https
      protocol: TCP

---
# DNS Policy ì˜µì…˜
# ClusterFirst: í´ëŸ¬ìŠ¤í„° DNS ë¨¼ì € ì‚¬ìš© (ê¸°ë³¸ê°’)
# ClusterFirstWithHostNet: hostNetwork: trueì¼ ë•Œ
# Default: ë…¸ë“œì˜ DNS ì„¤ì • ì‚¬ìš©
# None: ìˆ˜ë™ DNS ì„¤ì •
apiVersion: v1
kind: Pod
metadata:
  name: custom-dns
spec:
  dnsPolicy: None
  dnsConfig:
    nameservers:
    - 1.1.1.1
    - 8.8.8.8
    searches:
    - example.com
    - my.domain.com
    options:
    - name: ndots
      value: "5"
    - name: edns0
  containers:
  - name: app
    image: nginx
```

### Pod ìŠ¤í† ë¦¬ì§€

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: storage-demo
spec:
  containers:
  - name: app
    image: nginx
    volumeMounts:
    # ConfigMap mount
    - name: config
      mountPath: /etc/nginx/conf.d
      readOnly: true
    
    # Secret mount
    - name: certs
      mountPath: /etc/ssl/certs
      readOnly: true
    
    # EmptyDir (ì„ì‹œ ì €ì¥)
    - name: cache
      mountPath: /cache
    
    # PVC mount
    - name: data
      mountPath: /usr/share/nginx/html
    
    # Projected volume
    - name: all-in-one
      mountPath: /combined
      readOnly: true
  
  volumes:
  # ConfigMap
  - name: config
    configMap:
      name: nginx-config
      defaultMode: 0644
  
  # Secret
  - name: certs
    secret:
      secretName: tls-certs
      defaultMode: 0400
  
  # EmptyDir
  - name: cache
    emptyDir:
      medium: Memory  # RAM ì‚¬ìš©
      sizeLimit: 100Mi
  
  # PersistentVolumeClaim
  - name: data
    persistentVolumeClaim:
      claimName: nginx-pvc
  
  # Projected (ì—¬ëŸ¬ ì†ŒìŠ¤ ê²°í•©)
  - name: all-in-one
    projected:
      sources:
      - secret:
          name: mysecret
          items:
          - key: username
            path: my-username
      - configMap:
          name: myconfig
          items:
          - key: config
            path: my-config
      - downwardAPI:
          items:
          - path: "labels"
            fieldRef:
              fieldPath: metadata.labels
```

---

## ğŸ“ Pod ìŠ¤ì¼€ì¤„ë§

### Node Selector

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: node-selector-demo
spec:
  nodeSelector:
    disktype: ssd
    zone: us-west-2a
  containers:
  - name: app
    image: nginx
```

### Node Affinity

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: node-affinity-demo
spec:
  affinity:
    nodeAffinity:
      # í•„ìˆ˜ ì¡°ê±´ (ìŠ¤ì¼€ì¤„ë§ ì‹œì )
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: kubernetes.io/os
            operator: In
            values: ["linux"]
          - key: node-role.kubernetes.io/worker
            operator: Exists
      
      # ì„ í˜¸ ì¡°ê±´ (ê°€ì¤‘ì¹˜ ê¸°ë°˜)
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
          - key: zone
            operator: In
            values: ["us-west-2a", "us-west-2b"]
      - weight: 50
        preference:
          matchExpressions:
          - key: disktype
            operator: In
            values: ["ssd"]
  
  containers:
  - name: app
    image: nginx
```

### Pod Affinity/Anti-Affinity

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-affinity-demo
  labels:
    app: web
spec:
  affinity:
    # Pod Affinity: íŠ¹ì • Podì™€ ê°™ì€ ë…¸ë“œì— ë°°ì¹˜
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values: ["cache"]
        topologyKey: kubernetes.io/hostname
        namespaceSelector:
          matchLabels:
            name: production
    
    # Pod Anti-Affinity: ë¶„ì‚° ë°°ì¹˜
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values: ["web"]
          topologyKey: kubernetes.io/hostname
  
  containers:
  - name: app
    image: nginx
```

### Taints and Tolerations

```yaml
# Nodeì— Taint ì¶”ê°€
# kubectl taint nodes node1 key=value:NoSchedule
# kubectl taint nodes node1 key=value:NoExecute
# kubectl taint nodes node1 key=value:PreferNoSchedule

apiVersion: v1
kind: Pod
metadata:
  name: toleration-demo
spec:
  tolerations:
  # íŠ¹ì • taint í—ˆìš©
  - key: "key"
    operator: "Equal"
    value: "value"
    effect: "NoSchedule"
  
  # GPU ë…¸ë“œ í—ˆìš©
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"
  
  # ëª¨ë“  taint í—ˆìš© (ì£¼ì˜!)
  - operator: "Exists"
  
  # NoExecute with tolerationSeconds
  - key: "temporary"
    operator: "Equal"
    value: "true"
    effect: "NoExecute"
    tolerationSeconds: 3600  # 1ì‹œê°„ í›„ eviction
  
  containers:
  - name: app
    image: nginx
```

### Priority and Preemption

```yaml
# PriorityClass ì •ì˜
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: high-priority
value: 1000
globalDefault: false
description: "High priority class for critical pods"

---
apiVersion: v1
kind: Pod
metadata:
  name: high-priority-pod
spec:
  priorityClassName: high-priority
  containers:
  - name: app
    image: nginx
```

---

## ğŸ¥ Health Checks

### Liveness Probe

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: liveness-probe-demo
spec:
  containers:
  - name: app
    image: myapp:1.0
    
    # HTTP GET probe
    livenessProbe:
      httpGet:
        path: /healthz
        port: 8080
        httpHeaders:
        - name: Custom-Header
          value: Awesome
      initialDelaySeconds: 30  # ì»¨í…Œì´ë„ˆ ì‹œì‘ í›„ ëŒ€ê¸°
      periodSeconds: 10         # ì²´í¬ ê°„ê²©
      timeoutSeconds: 5         # íƒ€ì„ì•„ì›ƒ
      successThreshold: 1       # ì„±ê³µ ì„ê³„ê°’
      failureThreshold: 3       # ì‹¤íŒ¨ ì„ê³„ê°’
    
    # TCP socket probe
    # livenessProbe:
    #   tcpSocket:
    #     port: 8080
    #   initialDelaySeconds: 15
    #   periodSeconds: 10
    
    # Exec command probe
    # livenessProbe:
    #   exec:
    #     command:
    #     - cat
    #     - /tmp/healthy
    #   initialDelaySeconds: 5
    #   periodSeconds: 5
```

### Readiness Probe

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: readiness-probe-demo
spec:
  containers:
  - name: app
    image: myapp:1.0
    
    # Readiness probe (íŠ¸ë˜í”½ ìˆ˜ì‹  ì¤€ë¹„ í™•ì¸)
    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 5
      successThreshold: 2  # 2ë²ˆ ì—°ì† ì„±ê³µ í•„ìš”
      failureThreshold: 3
    
    # Readiness Gate (ì¶”ê°€ ì¡°ê±´)
    readinessGates:
    - conditionType: "MyCustomCondition"
    
    ports:
    - containerPort: 8080
```

### Startup Probe (1.16+)

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: startup-probe-demo
spec:
  containers:
  - name: app
    image: slow-starting-app:1.0
    
    # Startup probe (ëŠë¦° ì‹œì‘ ì• í”Œë¦¬ì¼€ì´ì…˜ìš©)
    startupProbe:
      httpGet:
        path: /startup
        port: 8080
      initialDelaySeconds: 0
      periodSeconds: 10
      timeoutSeconds: 3
      successThreshold: 1
      failureThreshold: 30  # ìµœëŒ€ 30 * 10 = 300ì´ˆ ëŒ€ê¸°
    
    # Startupì´ ì„±ê³µí•œ í›„ì—ë§Œ ì‹¤í–‰
    livenessProbe:
      httpGet:
        path: /healthz
        port: 8080
      periodSeconds: 10
    
    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      periodSeconds: 5
```

---

## ğŸ” Pod ë³´ì•ˆ

### Security Context

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: security-context-demo
spec:
  # Pod ë ˆë²¨ ë³´ì•ˆ ì„¤ì •
  securityContext:
    runAsUser: 1000       # UID
    runAsGroup: 3000      # GID
    fsGroup: 2000         # ë³¼ë¥¨ íŒŒì¼ ê·¸ë£¹
    supplementalGroups: [4000]
    fsGroupChangePolicy: "OnRootMismatch"
    seccompProfile:
      type: RuntimeDefault
    seLinuxOptions:
      level: "s0:c123,c456"
  
  containers:
  - name: app
    image: nginx
    
    # Container ë ˆë²¨ ë³´ì•ˆ ì„¤ì • (Pod ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ)
    securityContext:
      runAsUser: 2000
      runAsNonRoot: true
      readOnlyRootFilesystem: true
      allowPrivilegeEscalation: false
      privileged: false
      capabilities:
        drop: ["ALL"]
        add: ["NET_BIND_SERVICE"]
      procMount: "Default"
    
    volumeMounts:
    - name: cache
      mountPath: /var/cache/nginx
    - name: run
      mountPath: /var/run
  
  volumes:
  - name: cache
    emptyDir: {}
  - name: run
    emptyDir: {}
```

### Pod Security Standards

```yaml
# Pod Security Standards (1.23+)
# Enforce: ìœ„ë°˜ ì‹œ ê±°ë¶€
# Audit: ê°ì‚¬ ë¡œê·¸ ê¸°ë¡
# Warn: ê²½ê³  ë©”ì‹œì§€

# Namespace ë ˆë²¨ ì ìš©
apiVersion: v1
kind: Namespace
metadata:
  name: secure-namespace
  labels:
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/enforce-version: latest
    pod-security.kubernetes.io/audit: restricted
    pod-security.kubernetes.io/audit-version: latest
    pod-security.kubernetes.io/warn: restricted
    pod-security.kubernetes.io/warn-version: latest

---
# Restricted ì •ì±… ì¤€ìˆ˜ Pod
apiVersion: v1
kind: Pod
metadata:
  name: restricted-pod
  namespace: secure-namespace
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 1000
    seccompProfile:
      type: RuntimeDefault
  
  containers:
  - name: app
    image: nginx:alpine
    securityContext:
      allowPrivilegeEscalation: false
      readOnlyRootFilesystem: true
      capabilities:
        drop: ["ALL"]
    
    volumeMounts:
    - name: tmp
      mountPath: /tmp
    - name: var-cache
      mountPath: /var/cache/nginx
    - name: var-run
      mountPath: /var/run
  
  volumes:
  - name: tmp
    emptyDir: {}
  - name: var-cache
    emptyDir: {}
  - name: var-run
    emptyDir: {}
```

---

## âœ… Best Practices

### 1. Resource Management

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: resource-managed-pod
spec:
  containers:
  - name: app
    image: myapp:1.0
    
    # Resource requests and limits
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
        ephemeral-storage: "1Gi"
      limits:
        memory: "256Mi"
        cpu: "200m"
        ephemeral-storage: "2Gi"
    
    # QoS Class
    # Guaranteed: requests == limits
    # Burstable: requests < limits
    # BestEffort: no requests/limits
```

### 2. Graceful Shutdown

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: graceful-shutdown-demo
spec:
  terminationGracePeriodSeconds: 60  # SIGTERM í›„ ëŒ€ê¸° ì‹œê°„
  
  containers:
  - name: app
    image: myapp:1.0
    
    # PreStop hook
    lifecycle:
      preStop:
        exec:
          command: ["/bin/sh", "-c", "sleep 15 && /app/graceful-shutdown.sh"]
    
    # Or HTTP preStop
    # lifecycle:
    #   preStop:
    #     httpGet:
    #       path: /shutdown
    #       port: 8080
```

### 3. Labels and Annotations

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: well-labeled-pod
  labels:
    # í‘œì¤€ ë ˆì´ë¸”
    app.kubernetes.io/name: myapp
    app.kubernetes.io/instance: myapp-prod
    app.kubernetes.io/version: "1.0.0"
    app.kubernetes.io/component: frontend
    app.kubernetes.io/part-of: myapp-suite
    app.kubernetes.io/managed-by: helm
    
    # ì»¤ìŠ¤í…€ ë ˆì´ë¸”
    environment: production
    tier: frontend
    team: platform
  
  annotations:
    # ì„¤ëª…ì  ë©”íƒ€ë°ì´í„°
    description: "Production frontend pod"
    prometheus.io/scrape: "true"
    prometheus.io/port: "9090"
    prometheus.io/path: "/metrics"
spec:
  containers:
  - name: app
    image: myapp:1.0
```

### 4. Service Account

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-service-account
  namespace: default
  annotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::123456789012:role/my-role

---
apiVersion: v1
kind: Pod
metadata:
  name: pod-with-sa
spec:
  serviceAccountName: my-service-account
  automountServiceAccountToken: true  # í† í° ìë™ ë§ˆìš´íŠ¸
  
  containers:
  - name: app
    image: myapp:1.0
    
    # ServiceAccount í† í° ìœ„ì¹˜
    # /var/run/secrets/kubernetes.io/serviceaccount/token
    # /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    # /var/run/secrets/kubernetes.io/serviceaccount/namespace
```

### 5. Debugging Pods

```yaml
# Debug ì»¨í…Œì´ë„ˆ ì¶”ê°€ (ephemeral container)
kubectl debug my-pod -it --image=busybox --target=my-container

# ë˜ëŠ” yamlë¡œ ì •ì˜
apiVersion: v1
kind: Pod
metadata:
  name: debug-pod
spec:
  shareProcessNamespace: true  # í”„ë¡œì„¸ìŠ¤ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ê³µìœ 
  
  containers:
  - name: app
    image: myapp:1.0
  
  # Debug sidecar
  - name: debug
    image: nicolaka/netshoot
    command: ["/bin/sleep", "3600"]
    securityContext:
      capabilities:
        add: ["SYS_PTRACE"]
```

---

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Podê°€ Pending ìƒíƒœ

```bash
# ì´ë²¤íŠ¸ í™•ì¸
kubectl describe pod my-pod

# ì¼ë°˜ì ì¸ ì›ì¸:
# 1. ë¦¬ì†ŒìŠ¤ ë¶€ì¡±
kubectl get nodes -o custom-columns=NAME:.metadata.name,CPU:.status.allocatable.cpu,MEMORY:.status.allocatable.memory

# 2. ì´ë¯¸ì§€ pull ì‹¤íŒ¨
kubectl get pod my-pod -o jsonpath='{.status.containerStatuses[0].state.waiting.reason}'

# 3. ìŠ¤ì¼€ì¤„ë§ ì œì•½
kubectl get pod my-pod -o jsonpath='{.spec.affinity}'
kubectl get nodes --show-labels
```

### CrashLoopBackOff

```bash
# ë¡œê·¸ í™•ì¸
kubectl logs my-pod --previous
kubectl logs my-pod -c my-container

# ìƒíƒœ í™•ì¸
kubectl get pod my-pod -o jsonpath='{.status.containerStatuses[0].lastState.terminated}'

# ì¬ì‹œì‘ íšŸìˆ˜ í™•ì¸
kubectl get pod my-pod -o jsonpath='{.status.containerStatuses[0].restartCount}'

# ì„ì‹œ í•´ê²°: ì¬ì‹œì‘ ì •ì±… ë³€ê²½
kubectl patch pod my-pod -p '{"spec":{"restartPolicy":"Never"}}'
```

### Pod Eviction

```bash
# Eviction ì´ìœ  í™•ì¸
kubectl get events --field-selector involvedObject.name=my-pod

# Node pressure í™•ì¸
kubectl describe node <node-name> | grep -A5 Conditions

# PDB (Pod Disruption Budget) í™•ì¸
kubectl get pdb
```

---

## ğŸ’¡ ê³ ê¸‰ íŒ

### 1. Ephemeral Containers (1.16+)

```bash
# ì‹¤í–‰ ì¤‘ì¸ Podì— ë””ë²„ê·¸ ì»¨í…Œì´ë„ˆ ì¶”ê°€
kubectl debug my-pod -it --image=busybox --target=my-container -- sh
```

### 2. Pod Presets (Deprecated, ëŒ€ì•ˆ: MutatingWebhook)

```yaml
# Webhookìœ¼ë¡œ ìë™ ì£¼ì… ì„¤ì •
apiVersion: v1
kind: ConfigMap
metadata:
  name: pod-preset-config
data:
  inject: |
    env:
    - name: DB_HOST
      value: postgres.default.svc
    - name: CACHE_HOST  
      value: redis.default.svc
```

### 3. Pod Overhead (1.18+)

```yaml
# RuntimeClass with overhead
apiVersion: node.k8s.io/v1
kind: RuntimeClass
metadata:
  name: kata-containers
handler: kata
overhead:
  podFixed:
    memory: "120Mi"
    cpu: "250m"

---
apiVersion: v1
kind: Pod
metadata:
  name: kata-pod
spec:
  runtimeClassName: kata-containers
  containers:
  - name: app
    image: myapp:1.0
```

---

> ğŸš€ PodëŠ” Kubernetesì˜ ê¸°ë³¸ ë‹¨ìœ„ë¡œ, ë‹¤ì–‘í•œ íŒ¨í„´ê³¼ ê¸°ëŠ¥ì„ ì´í•´í•˜ë©´ ê°•ë ¥í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!