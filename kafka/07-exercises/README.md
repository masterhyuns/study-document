# ğŸ¯ Kafka ì‹¤ìŠµ í”„ë¡œì íŠ¸

## ğŸ“š ì‹¤ìŠµ ëª©ë¡

### 1. ì£¼ë¬¸ ì²˜ë¦¬ ì‹œìŠ¤í…œ (Order Processing)
**íŒŒì¼**: `mini-projects/order-processing.js`  
**ë‚œì´ë„**: â­â­â­

ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ê¸°ë°˜ ì´ì»¤ë¨¸ìŠ¤ ì£¼ë¬¸ ì²˜ë¦¬ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

#### êµ¬ì„± ìš”ì†Œ:
- **Order Service**: ì£¼ë¬¸ ê´€ë¦¬
- **Payment Service**: ê²°ì œ ì²˜ë¦¬  
- **Inventory Service**: ì¬ê³  ê´€ë¦¬
- **Shipping Service**: ë°°ì†¡ ì²˜ë¦¬
- **Analytics Service**: ì‹¤ì‹œê°„ í†µê³„

#### í•™ìŠµ í¬ì¸íŠ¸:
- Event-driven ì•„í‚¤í…ì²˜
- Saga íŒ¨í„´ êµ¬í˜„
- ë³´ìƒ íŠ¸ëœì­ì…˜
- ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ì²˜ë¦¬

#### ì‹¤í–‰ ë°©ë²•:
```bash
# 1. Kafka í´ëŸ¬ìŠ¤í„° ì‹œì‘
cd ../01-setup
docker-compose up -d

# 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜
cd ../07-exercises/mini-projects
npm install kafkajs express uuid

# 3. ì‹œìŠ¤í…œ ì‹¤í–‰
node order-processing.js

# 4. í…ŒìŠ¤íŠ¸ ì£¼ë¬¸ ìƒì„±
curl -X POST http://localhost:3000/api/orders \
  -H "Content-Type: application/json" \
  -d '{
    "customerId": "CUST-001",
    "items": [
      {
        "productId": "ITEM-001",
        "name": "Laptop",
        "price": 1500,
        "quantity": 1
      }
    ]
  }'

# 5. ì£¼ë¬¸ ìƒíƒœ í™•ì¸
curl http://localhost:3000/api/orders/{orderId}

# 6. í†µê³„ í™•ì¸
curl http://localhost:3000/api/analytics
```

---

### 2. ì‹¤ì‹œê°„ ë¡œê·¸ ìˆ˜ì§‘ê¸° (Log Aggregator)
**ë‚œì´ë„**: â­â­

ì—¬ëŸ¬ ì„œë¹„ìŠ¤ì˜ ë¡œê·¸ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

#### êµ¬í˜„í•  ê¸°ëŠ¥:
```javascript
// ë¡œê·¸ ìˆ˜ì§‘ê¸° êµ¬ì¡°
class LogAggregator {
  // 1. ë¡œê·¸ ìˆ˜ì§‘
  collectLogs(source, logData) {
    // êµ¬ì¡°í™”ëœ ë¡œê·¸ ìƒì„±
    const log = {
      timestamp: new Date(),
      source,
      level: logData.level,
      message: logData.message,
      metadata: logData.metadata
    }
    
    // Kafkaë¡œ ì „ì†¡
    await this.producer.send({
      topic: 'application-logs',
      messages: [{ value: JSON.stringify(log) }]
    })
  }
  
  // 2. ë¡œê·¸ í•„í„°ë§
  filterByLevel(level) {
    // ERROR, WARN, INFO ë ˆë²¨ë³„ í•„í„°
  }
  
  // 3. ë¡œê·¸ ì§‘ê³„
  aggregateLogs() {
    // ì‹œê°„ëŒ€ë³„, ì„œë¹„ìŠ¤ë³„ ì§‘ê³„
  }
  
  // 4. ì•Œë¦¼
  alertOnError() {
    // ì—ëŸ¬ íŒ¨í„´ ê°ì§€ ì‹œ ì•Œë¦¼
  }
}
```

#### í•™ìŠµ í¬ì¸íŠ¸:
- ëŒ€ìš©ëŸ‰ ë¡œê·¸ ì²˜ë¦¬
- ì‹¤ì‹œê°„ í•„í„°ë§
- íŒ¨í„´ ë§¤ì¹­
- ì•Œë¦¼ ì‹œìŠ¤í…œ

---

### 3. ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ (Real-time Analytics)
**ë‚œì´ë„**: â­â­â­â­

ì›¹ì†Œì¼“ì„ í†µí•œ ì‹¤ì‹œê°„ ë°ì´í„° ëŒ€ì‹œë³´ë“œì…ë‹ˆë‹¤.

#### êµ¬í˜„í•  ê¸°ëŠ¥:
```javascript
// ì‹¤ì‹œê°„ ë¶„ì„ ì‹œìŠ¤í…œ
class RealTimeAnalytics {
  constructor() {
    this.metrics = {
      orders: { count: 0, revenue: 0 },
      users: { active: 0, new: 0 },
      performance: { avgResponseTime: 0, errorRate: 0 }
    }
  }
  
  // 1. ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
  async processStream() {
    // Kafka Streamsë¡œ ì‹¤ì‹œê°„ ì§‘ê³„
    stream
      .groupByKey()
      .window(60000) // 1ë¶„ ìœˆë„ìš°
      .aggregate(/* ì§‘ê³„ ë¡œì§ */)
  }
  
  // 2. WebSocket ì „ì†¡
  broadcastMetrics() {
    // ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ì— ì‹¤ì‹œê°„ ì „ì†¡
    this.wsClients.forEach(client => {
      client.send(JSON.stringify(this.metrics))
    })
  }
  
  // 3. ì´ìƒ íƒì§€
  detectAnomalies() {
    // í†µê³„ì  ì´ìƒì¹˜ íƒì§€
    if (metric > threshold) {
      this.sendAlert()
    }
  }
}
```

#### í•™ìŠµ í¬ì¸íŠ¸:
- Kafka Streams í™œìš©
- WebSocket ì—°ë™
- ì‹¤ì‹œê°„ ì§‘ê³„
- ì´ìƒ íƒì§€ ì•Œê³ ë¦¬ì¦˜

---

### 4. CDC (Change Data Capture) íŒŒì´í”„ë¼ì¸
**ë‚œì´ë„**: â­â­â­â­

ë°ì´í„°ë² ì´ìŠ¤ ë³€ê²½ì‚¬í•­ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ìº¡ì²˜í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

#### êµ¬í˜„ ì•„ì´ë””ì–´:
```javascript
// CDC íŒŒì´í”„ë¼ì¸
class CDCPipeline {
  // 1. ë³€ê²½ ê°ì§€
  captureChanges() {
    // DB íŠ¸ë¦¬ê±° ë˜ëŠ” í´ë§
  }
  
  // 2. ì´ë²¤íŠ¸ ë°œí–‰
  publishChangeEvent(change) {
    await producer.send({
      topic: 'db-changes',
      messages: [{
        value: JSON.stringify({
          operation: change.op, // INSERT, UPDATE, DELETE
          table: change.table,
          before: change.before,
          after: change.after,
          timestamp: change.ts
        })
      }]
    })
  }
  
  // 3. ë°ì´í„° ë™ê¸°í™”
  syncToDataLake() {
    // ë³€ê²½ì‚¬í•­ì„ ë°ì´í„° ë ˆì´í¬ì— ì ìš©
  }
  
  // 4. ìºì‹œ ë¬´íš¨í™”
  invalidateCache(change) {
    // ê´€ë ¨ ìºì‹œ í•­ëª© ë¬´íš¨í™”
  }
}
```

---

### 5. IoT ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ
**ë‚œì´ë„**: â­â­â­

IoT ì„¼ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ì²˜ë¦¬í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

#### êµ¬í˜„ ì•„ì´ë””ì–´:
```javascript
// IoT ë°ì´í„° ì²˜ë¦¬
class IoTDataProcessor {
  // 1. ì„¼ì„œ ë°ì´í„° ìˆ˜ì‹ 
  receiveSensorData(deviceId, data) {
    // ë°ì´í„° ê²€ì¦ ë° ì •ê·œí™”
  }
  
  // 2. ì‹œê³„ì—´ ì €ì¥
  storeTimeSeries(data) {
    // ì‹œê³„ì—´ DBì— ì €ì¥
  }
  
  // 3. ì‹¤ì‹œê°„ ì•Œë¦¼
  checkThresholds(data) {
    // ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ì•Œë¦¼
  }
  
  // 4. ì˜ˆì¸¡ ë¶„ì„
  predictMaintenance() {
    // ML ëª¨ë¸ë¡œ ì˜ˆë°© ì •ë¹„ ì‹œì  ì˜ˆì¸¡
  }
}
```

---

## ğŸ“ í•™ìŠµ ìˆœì„œ ê¶Œì¥ì‚¬í•­

### ì´ˆê¸‰ (1-2ì£¼ì°¨)
1. **ê¸°ë³¸ Producer/Consumer ì‘ì„±**
   - ë‹¨ìˆœ ë©”ì‹œì§€ ì „ì†¡/ìˆ˜ì‹ 
   - ì—ëŸ¬ ì²˜ë¦¬
   - ì„¤ì • ìµœì í™”

### ì¤‘ê¸‰ (3-4ì£¼ì°¨)  
2. **ì£¼ë¬¸ ì²˜ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„**
   - ì´ë²¤íŠ¸ ê¸°ë°˜ ì„¤ê³„
   - ì—¬ëŸ¬ ì„œë¹„ìŠ¤ ì—°ë™
   - íŠ¸ëœì­ì…˜ íŒ¨í„´

### ê³ ê¸‰ (5-6ì£¼ì°¨)
3. **ì‹¤ì‹œê°„ ë¶„ì„ ì‹œìŠ¤í…œ**
   - Kafka Streams ì‚¬ìš©
   - ë³µì¡í•œ ì§‘ê³„
   - ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ

### ì „ë¬¸ê°€ (7-8ì£¼ì°¨)
4. **í”„ë¡œë•ì…˜ ì¤€ë¹„**
   - ëª¨ë‹ˆí„°ë§ êµ¬í˜„
   - ì„±ëŠ¥ ìµœì í™”
   - ì¥ì•  ë³µêµ¬ ì‹œë‚˜ë¦¬ì˜¤

## ğŸ“ ê³¼ì œ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ê¸°ëŠ¥ êµ¬í˜„
- [ ] Event Sourcing íŒ¨í„´ ì ìš©
- [ ] CQRS íŒ¨í„´ êµ¬í˜„
- [ ] Saga íŒ¨í„´ìœ¼ë¡œ ë¶„ì‚° íŠ¸ëœì­ì…˜
- [ ] ë©±ë“±ì„± ë³´ì¥
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„

### ì„±ëŠ¥ ìµœì í™”
- [ ] ë°°ì¹˜ ì²˜ë¦¬ êµ¬í˜„
- [ ] ì••ì¶• ì ìš©
- [ ] íŒŒí‹°ì…˜ ì „ëµ ìµœì í™”
- [ ] Consumer Group ìŠ¤ì¼€ì¼ë§

### ëª¨ë‹ˆí„°ë§
- [ ] ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- [ ] ë¡œê·¸ ì§‘ê³„
- [ ] ì•Œë¦¼ ì„¤ì •
- [ ] ëŒ€ì‹œë³´ë“œ êµ¬ì„±

### í…ŒìŠ¤íŠ¸
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
- [ ] í†µí•© í…ŒìŠ¤íŠ¸
- [ ] ë¶€í•˜ í…ŒìŠ¤íŠ¸
- [ ] ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸

## ğŸš€ ì‹¤í–‰ í™˜ê²½

### í•„ìˆ˜ ìš”êµ¬ì‚¬í•­
- Docker & Docker Compose
- Node.js 18+
- Kafka í´ëŸ¬ìŠ¤í„° (3 ë¸Œë¡œì»¤)

### íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
npm init -y
npm install kafkajs express uuid winston
npm install --save-dev jest
```

### í™˜ê²½ ë³€ìˆ˜
```env
KAFKA_BROKERS=localhost:9092,localhost:9093,localhost:9094
KAFKA_CLIENT_ID=exercise-app
KAFKA_GROUP_ID=exercise-group
LOG_LEVEL=info
NODE_ENV=development
```

## ğŸ“š ì¶”ê°€ í•™ìŠµ ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [KafkaJS Documentation](https://kafka.js.org/)

### ì¶”ì²œ ë„ì„œ
- "Kafka: The Definitive Guide"
- "Designing Data-Intensive Applications"

### ì˜¨ë¼ì¸ ê°•ì¢Œ
- Confluent Kafka Tutorials
- Udemy Kafka Courses

## ğŸ’¡ íŒê³¼ íŠ¸ë¦­

### ë””ë²„ê¹…
```javascript
// ìƒì„¸ ë¡œê¹… í™œì„±í™”
const kafka = new Kafka({
  logLevel: logLevel.DEBUG,
  logCreator: customLogCreator
})

// ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ í™œìš©
consumer.on('consumer.fetch_start', () => {
  console.log('Fetching messages...')
})
```

### ì„±ëŠ¥ ì¸¡ì •
```javascript
// ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
const start = Date.now()
await processMessage(message)
const duration = Date.now() - start

// ë©”íŠ¸ë¦­ ê¸°ë¡
metrics.recordProcessingTime(duration)
```

### ì—ëŸ¬ ë³µêµ¬
```javascript
// Dead Letter Queue
async function handleError(message, error) {
  await producer.send({
    topic: 'dead-letter-queue',
    messages: [{
      value: JSON.stringify({
        originalMessage: message,
        error: error.message,
        timestamp: new Date()
      })
    }]
  })
}
```

---

ğŸ‰ **ì¶•í•˜í•©ë‹ˆë‹¤!** ì´ì œ Kafkaë¥¼ í™œìš©í•œ ì‹¤ì „ í”„ë¡œì íŠ¸ë¥¼ êµ¬í˜„í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤!