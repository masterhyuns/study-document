# ğŸŒŠ Kafka Streams í•™ìŠµ ê°€ì´ë“œ

## ğŸ¯ Kafka Streamsë€?

Kafka StreamsëŠ” Kafkaì— ì €ì¥ëœ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ë¶„ì„í•˜ê¸° ìœ„í•œ **í´ë¼ì´ì–¸íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬**ì…ë‹ˆë‹¤.

### í•µì‹¬ íŠ¹ì§•
- **ê²½ëŸ‰ ë¼ì´ë¸ŒëŸ¬ë¦¬**: ë³„ë„ í´ëŸ¬ìŠ¤í„° ë¶ˆí•„ìš”
- **Exactly-once ì²˜ë¦¬**: ì •í™•íˆ í•œ ë²ˆ ì²˜ë¦¬ ë³´ì¥
- **Stateful ì²˜ë¦¬**: ìƒíƒœ ì €ì¥ ë° ê´€ë¦¬
- **ì‹¤ì‹œê°„ ì²˜ë¦¬**: ë°€ë¦¬ì´ˆ ë‹¨ìœ„ ì§€ì—°

## ğŸ—ï¸ Streams vs Traditional Processing

### ì „í†µì ì¸ ë°°ì¹˜ ì²˜ë¦¬
```
Data Lake â†’ Batch Job (ë§¤ì¼ ì‹¤í–‰) â†’ Report
            (ëª‡ ì‹œê°„ ì†Œìš”)
```

### ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
```
Kafka â†’ Stream Processing â†’ Real-time Output
        (ë°€ë¦¬ì´ˆ ë‹¨ìœ„)
```

## ğŸ“Š í•µì‹¬ ê°œë…

### 1. Streamê³¼ Table

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           KStream (ë¬´í•œ ìŠ¤íŠ¸ë¦¼)        â”‚
â”‚  ì‹œê°„ â†’                              â”‚
â”‚  [Event1][Event2][Event3][Event4]... â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           KTable (ìƒíƒœ í…Œì´ë¸”)         â”‚
â”‚  Key    â”‚    Latest Value           â”‚
â”‚  user1  â”‚    { status: "active" }   â”‚
â”‚  user2  â”‚    { status: "inactive" } â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### KStream (ë ˆì½”ë“œ ìŠ¤íŠ¸ë¦¼)
- **ë¬´í•œí•œ ì´ë²¤íŠ¸ ì‹œí€€ìŠ¤**
- INSERTë§Œ ê°€ëŠ¥ (ì¶”ê°€ë§Œ)
- ëª¨ë“  ë ˆì½”ë“œ ìœ ì§€

#### KTable (ë³€ê²½ ë¡œê·¸ ìŠ¤íŠ¸ë¦¼)
- **ìµœì‹  ìƒíƒœë§Œ ìœ ì§€**
- UPDATE ê°€ëŠ¥
- í‚¤ë³„ ìµœì‹  ê°’ë§Œ ì €ì¥

#### GlobalKTable
- **ëª¨ë“  íŒŒí‹°ì…˜ ë°ì´í„° ë³µì œ**
- ì¡°ì¸ ì‹œ ìœ ìš©
- ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì¡°ì¸

### 2. Topology (í† í´ë¡œì§€)

```
Source Processor
      â”‚
      â–¼
Stream Processor 1 (Filter)
      â”‚
      â–¼
Stream Processor 2 (Map)
      â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â–¼             â–¼
Sink Processor 1   Sink Processor 2
(Output Topic A)   (Output Topic B)
```

## ğŸ”„ ì£¼ìš” Operations

### Stateless Operations (ë¬´ìƒíƒœ)

```javascript
// Filter - ì¡°ê±´ì— ë§ëŠ” ë ˆì½”ë“œë§Œ ì„ íƒ
stream.filter((key, value) => value.amount > 100)

// Map - ë ˆì½”ë“œ ë³€í™˜
stream.map((key, value) => {
  return { key: key.toUpperCase(), value: value * 2 }
})

// FlatMap - í•˜ë‚˜ì˜ ë ˆì½”ë“œë¥¼ ì—¬ëŸ¬ ê°œë¡œ ë¶„í• 
stream.flatMap((key, value) => {
  return value.items.map(item => [key, item])
})

// Branch - ìŠ¤íŠ¸ë¦¼ ë¶„ê¸°
const branches = stream.branch(
  (key, value) => value.type === 'A',  // branch 0
  (key, value) => value.type === 'B',  // branch 1
  (key, value) => true                 // branch 2 (ë‚˜ë¨¸ì§€)
)
```

### Stateful Operations (ìƒíƒœìœ ì§€)

```javascript
// GroupBy - í‚¤ë¡œ ê·¸ë£¹í™”
stream.groupByKey()

// Aggregate - ì§‘ê³„
grouped.aggregate(
  () => 0,  // ì´ˆê¸°ê°’
  (key, value, aggregate) => aggregate + value.amount
)

// Count - ê°œìˆ˜ ì„¸ê¸°
grouped.count()

// Reduce - ë¦¬ë“€ìŠ¤
grouped.reduce((aggValue, newValue) => aggValue + newValue)

// Join - ì¡°ì¸
stream1.join(
  stream2,
  (value1, value2) => ({ ...value1, ...value2 }),
  JoinWindows.of(Duration.ofMinutes(5))
)
```

## â° Windowing (ìœˆë„ìš°)

### ìœˆë„ìš° íƒ€ì…

```
1. Tumbling Window (ê³ ì • ìœˆë„ìš°)
   |--5ë¶„--|--5ë¶„--|--5ë¶„--|
   
2. Hopping Window (ì´ë™ ìœˆë„ìš°)
   |--10ë¶„--|
      |--10ë¶„--|
         |--10ë¶„--|
   (5ë¶„ë§ˆë‹¤ ì´ë™)
   
3. Sliding Window (ìŠ¬ë¼ì´ë”© ìœˆë„ìš°)
   ì—°ì†ì ìœ¼ë¡œ ì´ë™
   
4. Session Window (ì„¸ì…˜ ìœˆë„ìš°)
   |--í™œë™--|gap|--í™œë™--|gap|
   (ë¹„í™œë™ ê¸°ê°„ìœ¼ë¡œ êµ¬ë¶„)
```

### ìœˆë„ìš° ì˜ˆì œ

```javascript
// 5ë¶„ ë‹¨ìœ„ Tumbling Window
stream
  .groupByKey()
  .windowedBy(TimeWindows.of(Duration.ofMinutes(5)))
  .count()

// 10ë¶„ ìœˆë„ìš°, 5ë¶„ë§ˆë‹¤ ì´ë™í•˜ëŠ” Hopping Window  
stream
  .groupByKey()
  .windowedBy(TimeWindows
    .of(Duration.ofMinutes(10))
    .advanceBy(Duration.ofMinutes(5)))
  .aggregate(...)

// 30ë¶„ ë¹„í™œë™ í›„ ì„¸ì…˜ ì¢…ë£Œ
stream
  .groupByKey()
  .windowedBy(SessionWindows.with(Duration.ofMinutes(30)))
  .count()
```

## ğŸ’¾ State Store

### Local State Store
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Application Instance   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Stream Process   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚            â”‚            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   State Store     â”‚  â”‚
â”‚  â”‚  (RocksDB/Memory) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Changelog Topic
```
State Store â†â†’ Changelog Topic (Kafka)
            (ìë™ ë°±ì—…/ë³µêµ¬)
```

## ğŸ¯ ì‹¤ì „ ì˜ˆì œ

### 1. ì‹¤ì‹œê°„ ë§¤ì¶œ ì§‘ê³„

```javascript
const salesStream = builder.stream('sales-events')

// ì‹œê°„ë³„ ë§¤ì¶œ ì§‘ê³„
const hourlySales = salesStream
  .groupByKey()
  .windowedBy(TimeWindows.of(Duration.ofHours(1)))
  .aggregate(
    () => ({ count: 0, total: 0 }),
    (key, value, agg) => ({
      count: agg.count + 1,
      total: agg.total + value.amount
    })
  )
  
hourlySales.toStream().to('hourly-sales-output')
```

### 2. ì‚¬ìš©ì ì„¸ì…˜ ë¶„ì„

```javascript
const clickStream = builder.stream('user-clicks')

// 30ë¶„ ì„¸ì…˜ ìœˆë„ìš°ë¡œ ì‚¬ìš©ì í™œë™ ì¶”ì 
const userSessions = clickStream
  .groupBy((key, value) => value.userId)
  .windowedBy(SessionWindows.with(Duration.ofMinutes(30)))
  .aggregate(
    () => ({
      clicks: [],
      duration: 0,
      pages: new Set()
    }),
    (userId, click, session) => ({
      clicks: [...session.clicks, click],
      duration: click.timestamp - session.clicks[0]?.timestamp || 0,
      pages: session.pages.add(click.page)
    })
  )
```

### 3. ì¡°ì¸ ì˜ˆì œ

```javascript
// ì£¼ë¬¸ê³¼ ê²°ì œ ì¡°ì¸
const orders = builder.stream('orders')
const payments = builder.stream('payments')

const paidOrders = orders.join(
  payments,
  (order, payment) => ({
    orderId: order.id,
    amount: order.amount,
    paymentMethod: payment.method,
    paidAt: payment.timestamp
  }),
  JoinWindows.of(Duration.ofMinutes(10))
)
```

## ğŸš€ Kafka Streams Application

### ê¸°ë³¸ êµ¬ì¡°

```javascript
import { KafkaStreams } from 'kafka-streams'

// 1. ì„¤ì •
const config = {
  applicationId: 'my-stream-app',
  bootstrapServers: 'localhost:9092',
  defaultKeySerde: 'string',
  defaultValueSerde: 'json'
}

// 2. í† í´ë¡œì§€ ì •ì˜
const builder = new StreamsBuilder()

const sourceStream = builder.stream('input-topic')

const processedStream = sourceStream
  .filter((key, value) => value.amount > 100)
  .mapValues(value => ({
    ...value,
    processed: true,
    timestamp: new Date()
  }))

processedStream.to('output-topic')

// 3. ì‹¤í–‰
const topology = builder.build()
const streams = new KafkaStreams(topology, config)

await streams.start()

// 4. ì¢…ë£Œ ì²˜ë¦¬
process.on('SIGTERM', async () => {
  await streams.close()
})
```

## ğŸ“Š KSQL/ksqlDB

### KSQLì´ë€?
- **SQLë¡œ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬**
- Kafka Streams ìœ„ì— êµ¬ì¶•ëœ SQL ì—”ì§„
- ì½”ë“œ ì—†ì´ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ê°€ëŠ¥

### KSQL vs Kafka Streams

| íŠ¹ì§• | KSQL | Kafka Streams |
|------|------|---------------|
| ì–¸ì–´ | SQL | Java/Scala |
| ë°°í¬ | ì„œë²„ í´ëŸ¬ìŠ¤í„° | ì„ë² ë””ë“œ ë¼ì´ë¸ŒëŸ¬ë¦¬ |
| ìœ ì—°ì„± | ì œí•œì  | ì™„ì „í•œ ì œì–´ |
| í•™ìŠµê³¡ì„  | ë‚®ìŒ | ë†’ìŒ |

### KSQL ì˜ˆì œ

```sql
-- Stream ìƒì„±
CREATE STREAM orders (
  orderId VARCHAR,
  userId VARCHAR,
  amount DOUBLE,
  timestamp BIGINT
) WITH (
  KAFKA_TOPIC='orders',
  VALUE_FORMAT='JSON'
);

-- Table ìƒì„±
CREATE TABLE users (
  userId VARCHAR PRIMARY KEY,
  name VARCHAR,
  email VARCHAR
) WITH (
  KAFKA_TOPIC='users',
  VALUE_FORMAT='JSON'
);

-- ì‹¤ì‹œê°„ ì§‘ê³„
CREATE TABLE order_totals AS
  SELECT 
    userId,
    COUNT(*) as order_count,
    SUM(amount) as total_amount
  FROM orders
  WINDOW TUMBLING (SIZE 1 HOUR)
  GROUP BY userId;

-- Stream-Table ì¡°ì¸
CREATE STREAM enriched_orders AS
  SELECT 
    o.orderId,
    o.amount,
    u.name as userName,
    u.email
  FROM orders o
  LEFT JOIN users u ON o.userId = u.userId;

-- í•„í„°ë§
CREATE STREAM large_orders AS
  SELECT * FROM orders
  WHERE amount > 1000;
```

## ğŸ¯ ì‚¬ìš© ì‚¬ë¡€

### 1. ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ
```
Kafka â†’ Streams Processing â†’ Time Series DB â†’ Grafana
                          â””â†’ WebSocket â†’ React Dashboard
```

### 2. ì´ìƒ íƒì§€
```
Sensor Data â†’ Kafka â†’ Stream Analytics â†’ Alert System
                    â””â†’ ML Model â†’ Anomaly Detection
```

### 3. ETL íŒŒì´í”„ë¼ì¸
```
Source DB â†’ CDC â†’ Kafka â†’ Stream Transform â†’ Target DB
                        â””â†’ Data Lake
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### 1. íŒŒí‹°ì…”ë‹
```javascript
// Co-partitioningìœ¼ë¡œ ì¡°ì¸ ìµœì í™”
stream1.through('repartitioned-topic', 
  Produced.with(Serdes.String(), Serdes.JSON())
    .withStreamPartitioner((topic, key, value) => 
      Math.abs(key.hashCode()) % numPartitions
    )
)
```

### 2. State Store íŠœë‹
```javascript
// RocksDB ì„¤ì • ìµœì í™”
const storeSupplier = Stores.persistentKeyValueStore('my-store')
  .withCachingEnabled()  // ìºì‹± í™œì„±í™”
  .withLoggingEnabled()   // ë³€ê²½ ë¡œê·¸ í™œì„±í™”
```

### 3. ì²˜ë¦¬ ë³´ì¥
```javascript
// Exactly-once ì²˜ë¦¬
config.processingGuarantee = 'exactly_once_v2'
config.transactionalId = 'my-transactional-id'
```

## ğŸ§ª í…ŒìŠ¤íŠ¸

### TopologyTestDriver
```javascript
// í† í´ë¡œì§€ í…ŒìŠ¤íŠ¸
const testDriver = new TopologyTestDriver(topology, config)

const inputTopic = testDriver.createInputTopic('input', 
  Serdes.String(), Serdes.JSON())
  
const outputTopic = testDriver.createOutputTopic('output',
  Serdes.String(), Serdes.JSON())

// í…ŒìŠ¤íŠ¸ ë°ì´í„° ì…ë ¥
inputTopic.pipeInput('key1', { value: 100 })

// ê²°ê³¼ ê²€ì¦
const output = outputTopic.readRecord()
expect(output.value).toEqual({ value: 100, processed: true })
```

## ğŸ“ í•™ìŠµ ê²½ë¡œ

1. **ê¸°ë³¸ Operations ìµíˆê¸°**
   - Filter, Map, GroupBy
   - ê°„ë‹¨í•œ í† í´ë¡œì§€ êµ¬ì„±

2. **Stateful Processing**
   - Aggregation
   - Windowing
   - State Store ì´í•´

3. **ê³ ê¸‰ ê¸°ëŠ¥**
   - Join operations
   - Custom processors
   - Error handling

4. **í”„ë¡œë•ì…˜ ì¤€ë¹„**
   - ëª¨ë‹ˆí„°ë§
   - ì„±ëŠ¥ íŠœë‹
   - ì¥ì•  ë³µêµ¬

## ğŸ“š ì‹¤ìŠµ íŒŒì¼

- `kafka-streams/basic-stream.js` - ê¸°ë³¸ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
- `kafka-streams/windowing.js` - ìœˆë„ìš° ì²˜ë¦¬
- `kafka-streams/join-example.js` - ì¡°ì¸ ì˜ˆì œ
- `ksql/queries.sql` - KSQL ì¿¼ë¦¬ ëª¨ìŒ

---

ğŸ’¡ **ë‹¤ìŒ ë‹¨ê³„**: Streamsë¥¼ ë§ˆìŠ¤í„°í–ˆë‹¤ë©´ [ì‹¤ì „ íŒ¨í„´](../05-patterns/README.md)ì„ í•™ìŠµí•˜ì„¸ìš”!