# 🚀 Apache Kafka 핵심 개념 가이드

## 📖 카프카란 무엇인가?

Apache Kafka는 **실시간 데이터 스트리밍 플랫폼**입니다.  
LinkedIn에서 개발되어 현재는 Apache 재단의 오픈소스 프로젝트로 관리되고 있습니다.

### 🎯 카프카를 한 문장으로 표현하면?
> "대용량 실시간 데이터를 안전하고 빠르게 전달하는 고속도로"

## 🏗️ 핵심 구성 요소

### 1. 메시지 (Message) 📨
```
┌─────────────────────────┐
│  Key: "user-123"        │  ← 메시지 라우팅용 키
│  Value: {               │  ← 실제 데이터
│    "action": "purchase",│
│    "item": "laptop"     │
│  }                      │
│  Timestamp: 1699123456  │  ← 시간 정보
└─────────────────────────┘
```
- **카프카의 기본 데이터 단위**
- Key-Value 형태로 구성
- 최대 1MB 크기 제한 (기본값)

### 2. 토픽 (Topic) 📂
```
┌──────────────────────────────────────────┐
│            Topic: "user-events"          │
├──────────────────────────────────────────┤
│  Partition 0: [msg1] [msg4] [msg7] ...   │
│  Partition 1: [msg2] [msg5] [msg8] ...   │
│  Partition 2: [msg3] [msg6] [msg9] ...   │
└──────────────────────────────────────────┘
```
- **메시지를 구분하는 논리적 단위**
- 데이터베이스의 테이블과 유사한 개념
- 여러 파티션으로 구성되어 병렬 처리 가능

### 3. 파티션 (Partition) 🔀
```
Partition 0: 
┌────┬────┬────┬────┬────┬────┐
│ 0  │ 1  │ 2  │ 3  │ 4  │ 5  │ ← Offset (메시지 위치)
└────┴────┴────┴────┴────┴────┘
 old ───────────────────→ new
```
- **토픽을 나누는 물리적 단위**
- 순서가 보장되는 메시지 큐
- 각 메시지는 고유한 offset을 가짐

### 4. 브로커 (Broker) 🖥️
```
         Kafka Cluster
┌────────────────────────────┐
│  Broker 1    Broker 2      │
│  ┌──────┐    ┌──────┐      │
│  │Topic1│    │Topic2│      │
│  │Part0 │    │Part1 │      │
│  └──────┘    └──────┘      │
│                            │
│  Broker 3    Broker 4      │
│  ┌──────┐    ┌──────┐      │
│  │Topic1│    │Topic2│      │
│  │Part1 │    │Part0 │      │
│  └──────┘    └──────┘      │
└────────────────────────────┘
```
- **카프카 서버 인스턴스**
- 메시지 저장 및 전달 담당
- 여러 브로커가 클러스터 구성

## 🔄 데이터 흐름 아키텍처

```
┌─────────────┐      ┌─────────────┐      ┌─────────────┐
│  Producer   │─────▶│    Kafka    │─────▶│  Consumer   │
│  (데이터    │      │   Cluster   │      │  (데이터    │
│   생산자)   │      │  (중앙 허브) │      │   소비자)   │
└─────────────┘      └─────────────┘      └─────────────┘
      ▲                     │                     │
      │                     ▼                     ▼
   [웹 서버]          [데이터 저장소]        [분석 시스템]
   [IoT 기기]          [복제/백업]          [모니터링]
   [모바일 앱]         [장기 보관]          [알림 서비스]
```

### Producer (프로듀서) 📤
- **데이터를 카프카로 보내는 애플리케이션**
- 어떤 토픽, 어떤 파티션에 보낼지 결정
- 전송 보장 수준 설정 가능

### Consumer (컨슈머) 📥
- **카프카에서 데이터를 읽는 애플리케이션**
- 특정 토픽을 구독(subscribe)
- Consumer Group으로 묶어 병렬 처리 가능

### Consumer Group 👥
```
        Topic (3 Partitions)
┌─────────┬─────────┬─────────┐
│ Part 0  │ Part 1  │ Part 2  │
└────┬────┴────┬────┴────┬────┘
     │         │         │
  Consumer Group "analytics"
     │         │         │
┌────▼────┬────▼────┬────▼────┐
│Consumer1│Consumer2│Consumer3│
└─────────┴─────────┴─────────┘
```
- **여러 컨슈머를 논리적으로 묶은 단위**
- 각 파티션은 그룹 내 하나의 컨슈머만 읽음
- 자동 로드 밸런싱 및 장애 복구

## 💪 카프카의 핵심 특징

### 1. 높은 처리량 (High Throughput) ⚡
- 초당 수백만 건의 메시지 처리
- 순차 I/O와 페이지 캐시 활용

### 2. 확장성 (Scalability) 📈
- 브로커와 파티션을 추가하여 수평 확장
- 무중단 확장 가능

### 3. 내구성 (Durability) 💾
- 디스크에 메시지 저장
- 복제(Replication)를 통한 데이터 보호

### 4. 실시간성 (Real-time) ⏱️
- 밀리초 단위의 낮은 지연시간
- 스트림 처리에 최적화

## 🎯 주요 사용 사례

### 1. 실시간 데이터 파이프라인 🚇
```
[소스 시스템] → Kafka → [타겟 시스템]
   MySQL    →  Kafka  → Elasticsearch
   API      →  Kafka  → Data Lake
```

### 2. 이벤트 소싱 📝
```
User Action → Event → Kafka → Event Store
                    ↓
              Event Handlers
              (알림, 분석, 로깅)
```

### 3. 로그 수집 📊
```
Application Logs ─┐
System Logs ──────┼──→ Kafka → Log Analytics
Access Logs ──────┘
```

### 4. 마이크로서비스 통신 🔗
```
Service A ─→ Kafka ←─ Service B
             ↑ ↓
         Service C
```

## 🔑 핵심 개념 요약

| 개념 | 설명 | 비유 |
|------|------|------|
| **Topic** | 메시지 카테고리 | 📁 폴더 |
| **Partition** | 토픽의 물리적 분할 | 📑 폴더 내 파일 |
| **Offset** | 파티션 내 메시지 위치 | 📍 페이지 번호 |
| **Producer** | 데이터 생산자 | 📮 우체부 |
| **Consumer** | 데이터 소비자 | 📬 수신자 |
| **Broker** | 카프카 서버 | 🏢 우체국 |
| **Cluster** | 브로커들의 집합 | 🏙️ 우체국 네트워크 |

## 🚦 시작하기 전 알아야 할 것

### ✅ 카프카가 적합한 경우
- 대용량 실시간 데이터 처리
- 시스템 간 느슨한 결합 필요
- 이벤트 기반 아키텍처 구축
- 데이터 스트리밍 및 분석

### ❌ 카프카가 부적합한 경우
- 소량의 데이터 처리
- 동기식 요청-응답 패턴
- 복잡한 쿼리가 필요한 경우
- 트랜잭션이 중요한 경우

## 🎓 다음 학습 단계

1. **환경 구축** → [01-setup](../01-setup/README.md)
2. **Producer 실습** → [02-producer](../02-producer/README.md)
3. **Consumer 실습** → [03-consumer](../03-consumer/README.md)
4. **스트림 처리** → [04-streaming](../04-streaming/README.md)

---

💡 **학습 팁**: 각 개념을 하나씩 실습하면서 이해하는 것이 중요합니다. 다음 단계로 넘어가기 전에 현재 개념을 확실히 이해했는지 확인하세요!